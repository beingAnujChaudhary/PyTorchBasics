{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVl6byAXEtrhYKkBkscDLu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# ðŸ“¦ Dataset & DataLoader in PyTorch\n","\n","---\n","\n","## âŒ Problems with Naive (Full-Batch) Training\n","\n","Training on the **entire dataset at once** causes:\n","\n","1. **Memory inefficiency**\n","\n","   * Entire dataset must fit in RAM / GPU memory.\n","\n","2. **Poor convergence behavior**\n","\n","   * Updates happen rarely â†’ slower & unstable learning.\n","\n","### âœ… Solution\n","\n","ðŸ‘‰ **Train using mini-batches** instead of full data.\n","\n","---\n","\n","## ðŸ§  Simple Manual Mini-Batch Approach (Why Itâ€™s Not Ideal)\n","\n","You *can* manually create batches using loops and slicing:\n","\n","* Loop over epochs\n","* Slice tensors into chunks of `batch_size`\n","* Forward â†’ loss â†’ backward â†’ optimizer step\n","\n","### âš ï¸ Problems with this approach\n","\n","1. âŒ No standard interface for data\n","2. âŒ No easy way to apply transformations\n","3. âŒ No built-in shuffling & sampling\n","4. âŒ No parallel data loading\n","5. âŒ Batch logic clutters training loop\n","\n","ðŸ‘‰ **This is why PyTorch gives us Dataset & DataLoader**\n","\n","---\n","\n","## ðŸ§© Core Idea: Dataset vs DataLoader\n","\n","> **Dataset** = *What is the data & how to get one sample*\n","> **DataLoader** = *How to iterate efficiently over the data*\n","\n","---\n"],"metadata":{"id":"xxlS8_Pi-mHk"}},{"cell_type":"markdown","source":["\n","## ðŸ“˜ Dataset Class (Blueprint for Data)\n","\n","The **Dataset** class (`torch.utils.data.Dataset`) defines **how data is accessed** (how to read data and its size.).\n","\n","### Must implement 3 methods:\n","\n","```python\n","__init__()      # how data is loaded Initialize data, file paths, or transforms\n","__len__()       # total number of samples\n","__getitem__(i) # returns sample (and label) at index i\n","```\n","\n","### Key Intuition\n","\n","* Dataset knows **nothing about batching**\n","* It only knows **â€œgiven an index, return one sampleâ€**\n","\n","---\n","\n"],"metadata":{"id":"PwRqmc4V-wqQ"}},{"cell_type":"markdown","source":["```\n","# Example Structure\n","class CustomDataset(Dataset):\n","    def __init__(self, features, labels):\n","        self.features = features\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return self.features.shape[0]\n","\n","    def __getitem__(self, index):\n","        # Apply transforms here if needed\n","        return self.features[index], self.labels[index]\n","```"],"metadata":{"id":"u-sXJgAt_jIz"}},{"cell_type":"markdown","source":["## ðŸšš DataLoader Class (Data Pipeline Manager)\n","\n","The **DataLoader Class (`torch.utils.data.DataLoader`) wraps a Dataset** and handles:\n","\n","* âœ… Batching\n","* âœ… Shuffling\n","* âœ… Parallel loading\n","* âœ… Efficient iteration\n","\n","### Typical Training Loop\n","\n","```python\n","for batch_x, batch_y in dataloader:\n","    # forward\n","    # loss\n","    # backward\n","    # optimizer step\n","```\n","\n","âž¡ï¸ Clean, readable, production-ready\n","\n","---\n","\n","## ðŸ” DataLoader Control Flow (Per Epoch)\n","\n","1. **Shuffle indices**: At the start of an epoch, indices are shuffled (if `shuffle=True`)\n","2. **Chunking**: Indices are divided into chunks of `batch_size`.\n","3. For each batch:\n","\n","   * **Fetching**: Samples are fetched from the Dataset using `__getitem__` for the indices in the chunk\n","   * Collect samples\n","   * **Collation**: Samples are combined into a single batch (using `collate_fn`).\n","4. **Yield**: The batch is returned to the training loop.\n","\n","---\n"],"metadata":{"id":"qgm_EoPa-0jf"}},{"cell_type":"markdown","source":["\n","## âš™ï¸ Parallel Data Loading (`num_workers`)\n","\n","DataLoader can use multiple processes (`num_workers`) to speed up data retrieval.\n","\n","### Example Setup\n","\n","* Total samples = **10,000**\n","* Batch size = **32**\n","* num_workers = **4**\n","* â‰ˆ **312 batches / epoch**\n","\n","### What Happens?\n","\n","* Main process creates batch index lists\n","* Workers load batches **in parallel**\n","* While GPU trains on batch 1:\n","\n","  * Workers prepare batch 2, 3, 4â€¦\n","* Result: **Pipeline effect â†’ no idle GPU**\n","\n","âœ… Faster training\n","âœ… Better CPU utilization\n","\n"],"metadata":{"id":"biO_bDanA4Ea"}},{"cell_type":"markdown","source":["---\n","\n","## ðŸŽ¯ Samplers (How Indices Are Chosen)\n","\n","Samplers determine the strategy for drawing samples from the dataset.\n","\n","### Built-in Samplers\n","\n","1. **SequentialSampler**\n","\n","   * Samples in order: `0, 1, 2, ...`\n","   * Default when `shuffle=False`\n","\n","2. **RandomSampler**\n","\n","   * Random order (no replacement)\n","   * Default when `shuffle=True`\n","3. **Custom Samplers**\n","   * Useful for handling imbalanced datasets or specific requirements (e.g., time series).\n","\n","### Why Custom Samplers?\n","\n","* Imbalanced datasets\n","* Time-series data\n","* Class-balanced sampling\n","\n","---\n","\n"],"metadata":{"id":"tZZpgyjHBOCG"}},{"cell_type":"markdown","source":["## ðŸ§© `collate_fn` (How Samples Become a Batch)\n","\n","### What is `collate_fn`?\n","\n","A function that **combines individual samples into a batch**.\n","\n","* Default: simple stacking\n","* Custom: padding, masking, special formats\n","\n","### Common Use Case: NLP Padding\n","\n","Different sentence lengths â†’ need padding before batching.\n","\n","```text\n","[1, 2, 3]\n","[4, 5]\n","[6, 7, 8, 9]\n","```\n","\n","âž¡ï¸ `collate_fn` pads them to equal length\n","\n","---\n","\n"],"metadata":{"id":"y3DIU-bV-6WL"}},{"cell_type":"markdown","source":["## âš™ï¸ Important DataLoader Parameters\n","\n","| Parameter     | Meaning                    |\n","| ------------- | -------------------------- |\n","| `dataset`     | The source dataset (must implement `__len__`, `__getitem__)` |\n","| `batch_size`  | Number of samples per batch. Larger sizes speed up GPU training but use more memory.          |\n","| `shuffle`     | If `True`, reshuffles data every epoch. Crucial to prevent model bias based on order.   |\n","| `num_workers` | Number of subprocesses for loading. Set `>0` to utilize multi-core CPUs and reduce bottlenecks.|\n","| `pin_memory`  | If `True`, copies tensors to pinned (page-locked) memory. Improves transfer speed to CUDA (GPU) devices.|\n","| `drop_last`   | If `True`, drops the last incomplete batch if dataset size isn't divisible by batch size (useful for Batch Norm).|\n","| `collate_fn`  | Custom batch creation      |\n","| `sampler`     | Custom sampling logic      |\n","\n","---\n","\n"],"metadata":{"id":"DxhcfS4mB2aV"}},{"cell_type":"markdown","source":["## ðŸ§  Mental Model (Very Important)\n","\n","```\n","Dataset        â†’ defines \"ONE sample\"\n","DataLoader     â†’ defines \"HOW batches flow\"\n","Sampler        â†’ defines \"WHICH samples\"\n","collate_fn     â†’ defines \"HOW samples combine\"\n","num_workers    â†’ defines \"HOW FAST data arrives\"\n","```\n","\n","---\n","\n","## âœ… Why This Matters (Exam + Production)\n","\n","* Clean separation of concerns\n","* Scales to large datasets\n","* Enables GPU-efficient training\n","* Industry-standard PyTorch pattern\n","\n","---"],"metadata":{"id":"raWxD0NxB4QL"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","import torch\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"v5uCzFJ_jNJK","executionInfo":{"status":"ok","timestamp":1767154391892,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# Step 1: Create a synthetic classification dataset using sklearn\n","# This mimics having raw data (like a CSV) before it enters the PyTorch pipeline.\n","# X -> feature matrix (inputs)\n","# y -> target labels (outputs)\n","X, y = make_classification(\n","    n_samples=10,       # Total number of rows (samples) in our dummy dataset\n","    n_features=2,       # Number of columns (input features) per sample\n","    n_informative=2,    # Features that actually predict the class\n","    n_redundant=0,      # Features that are random noise\n","    n_classes=2,        # Binary classification (0 or 1)\n","    random_state=42     # Ensures we get the exact same random numbers every time\n",")"],"metadata":{"id":"Dtf729OIjO8P","executionInfo":{"status":"ok","timestamp":1767154391909,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["print(X) # View feature matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EL9WoRf5koMK","executionInfo":{"status":"ok","timestamp":1767154391915,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ab451361-10e2-44f8-ca3a-55bf67e3f20f"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.06833894 -0.97007347]\n"," [-1.14021544 -0.83879234]\n"," [-2.8953973   1.97686236]\n"," [-0.72063436 -0.96059253]\n"," [-1.96287438 -0.99225135]\n"," [-0.9382051  -0.54304815]\n"," [ 1.72725924 -1.18582677]\n"," [ 1.77736657  1.51157598]\n"," [ 1.89969252  0.83444483]\n"," [-0.58723065 -1.97171753]]\n"]}]},{"cell_type":"code","source":["print(y) # View labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FPk3RMekpn8","executionInfo":{"status":"ok","timestamp":1767154391957,"user_tz":-330,"elapsed":32,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"869376a0-47d1-41ed-8f6c-1e70f3333f5a"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 0 0 1 1 1 1 0]\n"]}]},{"cell_type":"code","source":["# Display raw shapes for verification\n","# X shape will be (10, 2) and y shape will be (10,)\n","print(f\"Shape of X: {X.shape}\") # Shape of X -> (number_of_samples, number_of_features)\n","print(f\"Shape of y: {y.shape}\") # Shape of y -> (number_of_samples,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfiiVXYnjQDV","executionInfo":{"status":"ok","timestamp":1767154391966,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f0a5ef92-40fb-4afe-97f9-4340bc740bc1"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (10, 2)\n","Shape of y: (10,)\n"]}]},{"cell_type":"code","source":["# Step 2: Convert the data to PyTorch tensors\n","# PyTorch models require inputs as Tensors, not numpy arrays.\n","# float32 is standard for features; long (int64) is standard for classification labels.\n","X = torch.tensor(X, dtype=torch.float32) # Convert features to float tensor (required for neural networks)\n","y = torch.tensor(y, dtype=torch.long) # Convert labels to integer tensor\n","# dtype=torch.long is required for classification loss functions"],"metadata":{"id":"INQduFj_jRM3","executionInfo":{"status":"ok","timestamp":1767154391967,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["# Inspect tensors\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a67LaTiwl6UZ","executionInfo":{"status":"ok","timestamp":1767154391976,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"cb3f3218-541b-467a-9c5a-48a3bcc4d9b6"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.0683, -0.9701],\n","        [-1.1402, -0.8388],\n","        [-2.8954,  1.9769],\n","        [-0.7206, -0.9606],\n","        [-1.9629, -0.9923],\n","        [-0.9382, -0.5430],\n","        [ 1.7273, -1.1858],\n","        [ 1.7774,  1.5116],\n","        [ 1.8997,  0.8344],\n","        [-0.5872, -1.9717]])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQBgoYTul8Fg","executionInfo":{"status":"ok","timestamp":1767154391987,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"7dd6079d-ea9a-4de5-cb09-a9ae60dca101"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# The Dataset class acts as a blueprint. It decouples *how* we store/read data\n","# from *how* we use it in training.\n","class CustomDataset(Dataset):\n","    def __init__(self, features, labels):\n","        \"\"\"\n","        Initializes the dataset.\n","        Here we simply store the tensors we created above.\n","        In a real scenario, you might store file paths here instead of loading everything to RAM.\n","        \"\"\"\n","                # Store features and labels\n","\n","        self.features = features\n","        self.labels = labels\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the total number of samples in the dataset.\n","        DataLoader uses this to calculate how many batches are in an epoch.\n","        \"\"\"\n","                # Return total number of samples\n","\n","        return self.features.shape[0]   # Number of rows in features tensor\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Retrieves a single sample (features + label) at the specific 'index'.\n","        This method is called repeatedly by the DataLoader to construct a batch.\n","        \"\"\"\n","                # Return ONE sample (feature, label) at given index\n","\n","        return self.features[index], self.labels[index]"],"metadata":{"id":"0-E2VmzPjSWf","executionInfo":{"status":"ok","timestamp":1767154391989,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# Instantiate the custom dataset\n","dataset = CustomDataset(X, y) # Create dataset object"],"metadata":{"id":"kS7oU2A_k5-y","executionInfo":{"status":"ok","timestamp":1767154391992,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# Verification:  Total number of samples in dataset\n","print(f\"Dataset Length: {len(dataset)}\") # Should be 10\n","print(f\"Sample at index 2: {dataset[2]}\") # Returns tuple (tensor([x1, x2]), tensor(label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acCf4q4LjTzA","executionInfo":{"status":"ok","timestamp":1767154392012,"user_tz":-330,"elapsed":19,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"6bdb54ce-8d2b-453f-9b25-910e5fe68ac8"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Length: 10\n","Sample at index 2: (tensor([-2.8954,  1.9769]), tensor(0))\n"]}]},{"cell_type":"code","source":["# Get the 3rd sample (index = 2)\n","dataset[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5W4stYVamRGN","executionInfo":{"status":"ok","timestamp":1767154392026,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"315be362-b868-448f-b43d-05e10106a27f"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([-2.8954,  1.9769]), tensor(0))"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# Convert the data to PyTorch tensors\n","X = torch.tensor(X, dtype=torch.float32)\n","y = torch.tensor(y, dtype=torch.long)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lq16BQQ5jWir","executionInfo":{"status":"ok","timestamp":1767154392029,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"516d1529-e32b-4485-d561-0bd2b12ba483"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-392191959.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X = torch.tensor(X, dtype=torch.float32)\n","/tmp/ipython-input-392191959.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(y, dtype=torch.long)\n"]}]},{"cell_type":"code","source":["# The DataLoader wraps the Dataset to handle batching automatically.\n","# batch_size=2: It will fetch 2 samples at a time.\n","# shuffle=False: It will take samples sequentially (Index 0,1 then 2,3...).\n","dataloader = DataLoader(\n","    dataset,\n","    batch_size=2, # Number of samples per batch\n","    shuffle=False # Do not shuffle (keeps order)\n",")\n","\n","# Iterate through batches\n","print(\"\\nStarting Iteration over DataLoader:\")\n","print(\"=\"*50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"er2YjrdLjXYR","executionInfo":{"status":"ok","timestamp":1767154392037,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"8cd7cf23-46eb-4825-9efb-086e7f527226"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting Iteration over DataLoader:\n","==================================================\n"]}]},{"cell_type":"code","source":["# This loop simulates one 'epoch' of training.\n","# The DataLoader handles the complex logic of grabbing indices, fetching data via __getitem__,\n","# and collating them into batches .\n","for batch_features, batch_labels in dataloader:\n","    # batch_features shape: [2, 2] (batch_size, n_features)\n","    # batch_labels shape:   [2]    (batch_size)\n","    print(f\"Batch Features:\\n{batch_features}\")\n","    print(f\"Batch Labels:\\n{batch_labels}\")\n","    print(\"-\" * 50)\n","\n","# Since we have 10 samples and a batch size of 2, this loop runs exactly 5 times (10/2 = 5)."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hb0_uFn8jYVq","executionInfo":{"status":"ok","timestamp":1767154392040,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"3cc867f2-f361-4780-f122-79e11ff14b3d"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch Features:\n","tensor([[ 1.0683, -0.9701],\n","        [-1.1402, -0.8388]])\n","Batch Labels:\n","tensor([1, 0])\n","--------------------------------------------------\n","Batch Features:\n","tensor([[-2.8954,  1.9769],\n","        [-0.7206, -0.9606]])\n","Batch Labels:\n","tensor([0, 0])\n","--------------------------------------------------\n","Batch Features:\n","tensor([[-1.9629, -0.9923],\n","        [-0.9382, -0.5430]])\n","Batch Labels:\n","tensor([0, 1])\n","--------------------------------------------------\n","Batch Features:\n","tensor([[ 1.7273, -1.1858],\n","        [ 1.7774,  1.5116]])\n","Batch Labels:\n","tensor([1, 1])\n","--------------------------------------------------\n","Batch Features:\n","tensor([[ 1.8997,  0.8344],\n","        [-0.5872, -1.9717]])\n","Batch Labels:\n","tensor([1, 0])\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wiEvHd-MlL00","executionInfo":{"status":"ok","timestamp":1767154392041,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":62,"outputs":[]}]}