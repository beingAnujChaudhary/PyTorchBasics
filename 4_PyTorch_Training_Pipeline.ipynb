{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gaa7OgL-TdPa"
      },
      "outputs": [],
      "source": [
        "# Numerical computing library\n",
        "# Used for fast array operations and numerical calculations\n",
        "import numpy as np\n",
        "\n",
        "# Data manipulation and analysis library\n",
        "# Used for loading datasets, cleaning data, and tabular operations\n",
        "import pandas as pd\n",
        "\n",
        "# PyTorch library\n",
        "# Used for tensor operations, autograd, and building neural networks\n",
        "import torch\n",
        "\n",
        "# Utility to split dataset into training and testing sets\n",
        "# Ensures fair model evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Feature scaling utility\n",
        "# Standardizes features to have mean = 0 and std = 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Label encoding utility\n",
        "# Converts categorical labels into numerical form\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Breast Cancer dataset directly from a GitHub raw URL\n",
        "df = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv'\n",
        ")\n",
        "\n",
        "# Display the first 5 rows of the dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35b3pUI1Turc",
        "outputId": "9e28bd79-10ff-471f-81e3-d159bfff71ee"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
            "0  ...          17.33           184.60      2019.0            0.1622   \n",
            "1  ...          23.41           158.80      1956.0            0.1238   \n",
            "2  ...          25.53           152.50      1709.0            0.1444   \n",
            "3  ...          26.50            98.87       567.7            0.2098   \n",
            "4  ...          16.67           152.20      1575.0            0.1374   \n",
            "\n",
            "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
            "0             0.6656           0.7119                0.2654          0.4601   \n",
            "1             0.1866           0.2416                0.1860          0.2750   \n",
            "2             0.4245           0.4504                0.2430          0.3613   \n",
            "3             0.8663           0.6869                0.2575          0.6638   \n",
            "4             0.2050           0.4000                0.1625          0.2364   \n",
            "\n",
            "   fractal_dimension_worst  Unnamed: 32  \n",
            "0                  0.11890          NaN  \n",
            "1                  0.08902          NaN  \n",
            "2                  0.08758          NaN  \n",
            "3                  0.17300          NaN  \n",
            "4                  0.07678          NaN  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "\n",
        "# 569 â†’ number of rows (data samples)\n",
        "# 33 â†’ number of columns (features + labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTASXrxUTyeW",
        "outputId": "63352e61-ba47-45a5-dbb2-d81e7368cff8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns from the DataFrame\n",
        "df.drop(\n",
        "    columns=['id', 'Unnamed: 32'],  # Columns to remove\n",
        "    inplace=True                    # Modify the DataFrame directly\n",
        ")"
      ],
      "metadata": {
        "id": "VMgbJGUOT_SX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Yhb8eVUXeE",
        "outputId": "c78cc6f6-c1df-41c4-82a3-23683572ee07"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0         M        17.99         10.38          122.80     1001.0   \n",
            "1         M        20.57         17.77          132.90     1326.0   \n",
            "2         M        19.69         21.25          130.00     1203.0   \n",
            "3         M        11.42         20.38           77.58      386.1   \n",
            "4         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0         0.2419  ...         25.38          17.33           184.60   \n",
            "1         0.1812  ...         24.99          23.41           158.80   \n",
            "2         0.2069  ...         23.57          25.53           152.50   \n",
            "3         0.2597  ...         14.91          26.50            98.87   \n",
            "4         0.1809  ...         22.54          16.67           152.20   \n",
            "\n",
            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "V1G7UWSTSM4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.iloc[:, 1:],   # Features: all columns except the first one\n",
        "    df.iloc[:, 0],    # Target: first column (label)\n",
        "    test_size=0.2     # 20% data for testing, 80% for training\n",
        ")"
      ],
      "metadata": {
        "id": "rMX3fS-xUjDp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What each part means\n",
        "\n",
        "1. `df.iloc[:, 1:]`\n",
        "\n",
        "    * Selects all rows\n",
        "\n",
        "    * Selects columns from index 1 onward\n",
        "\n",
        "    * These are your input features (X)\n",
        "\n",
        "2. `df.iloc[:, 0]`\n",
        "\n",
        "    * Selects the first column\n",
        "\n",
        "    * This is your target/label (y) (e.g., diagnosis)\n",
        "\n",
        "3. `test_size=0.2`\n",
        "\n",
        "    * 20% of data â†’ test set\n",
        "\n",
        "    * 80% of data â†’ training set"
      ],
      "metadata": {
        "id": "3_UCXrqLzx0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling"
      ],
      "metadata": {
        "id": "4b4HNCjlSRwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler object\n",
        "# This scaler will normalize features to:\n",
        "# mean = 0 and standard deviation = 1\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler ONLY on training data\n",
        "# - Learns mean and std from X_train\n",
        "# - Transforms X_train using those statistics\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the SAME scaler\n",
        "# - Uses training mean and std\n",
        "# - Does NOT re-fit (prevents data leakage)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "9U6kQsjTU5ZE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### âš–ï¸ Feature Scaling with StandardScaler\n",
        "\n",
        "Feature scaling ensures that all input features are on a **similar scale**,\n",
        "which is critical for gradient-based models.\n",
        "\n",
        "---\n",
        "\n",
        "#### What Is Standardization?\n",
        "\n",
        "StandardScaler applies:\n",
        "```\n",
        "x_scaled = (x âˆ’ mean) / standard_deviation\n",
        "```\n",
        "\n",
        "**After scaling:**\n",
        "\n",
        "* Mean â‰ˆ 0\n",
        "* Standard deviation â‰ˆ 1\n",
        "\n",
        "**Without scaling:**\n",
        "\n",
        "* Large features dominate gradients\n",
        "* Training becomes unstable\n",
        "* Slower convergence\n",
        "\n",
        "**With scaling:**\n",
        "\n",
        "* Faster learning\n",
        "* Stable gradients\n",
        "* Better model performance\n",
        "\n",
        "**Models That Require Scaling**\n",
        "\n",
        "âœ” Logistic Regression\n",
        "\n",
        "âœ” Neural Networks\n",
        "\n",
        "âœ” SVM\n",
        "\n",
        "âœ” K-Means\n",
        "\n",
        "âŒ Tree-based models (Decision Trees, Random Forests)\n",
        "\n",
        "**Learn scaling rules from training data $\\rightarrow$ apply everywhere**"
      ],
      "metadata": {
        "id": "uauM1DHK0aZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train contains the training input features\n",
        "# It is the output after:\n",
        "# 1. Dropping unnecessary columns\n",
        "# 2. Splitting data into train/test\n",
        "# 3. Scaling features using StandardScaler\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMmrSA88VMZQ",
        "outputId": "7e9da8a7-ca6a-482b-de3f-12ef637314fc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02330827, -1.41765487, -0.0381396 , ..., -0.18039409,\n",
              "        -1.19845425, -0.61922761],\n",
              "       [-0.16184858, -0.13718557, -0.15830126, ...,  0.4414885 ,\n",
              "         0.97277489,  0.1388682 ],\n",
              "       [-0.06948837, -0.81643094, -0.11936386, ..., -1.21253805,\n",
              "        -1.67970607, -0.85707212],\n",
              "       ...,\n",
              "       [ 0.11523205, -0.64432485,  0.12263417, ...,  0.42186599,\n",
              "         0.22931278,  0.19202081],\n",
              "       [ 1.59010913,  3.01120847,  1.53987178, ...,  0.7403544 ,\n",
              "        -0.31429393, -0.45010567],\n",
              "       [-0.40429413, -0.50434523, -0.44384218, ..., -0.22552586,\n",
              "         0.57626176, -0.57788669]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWUcsPoF2ciY",
        "outputId": "ecdf9066-7a16-43a8-d434-6604706b27e3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ” Why It Looks Different Now\n",
        "\n",
        "Earlier, `X_train` was a **DataFrame**:\n",
        "\n",
        "```python\n",
        "X_train = df.iloc[:, 1:]\n",
        "```\n",
        "\n",
        "After this line:\n",
        "\n",
        "```python\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "```\n",
        "\n",
        "It became:\n",
        "\n",
        "```text\n",
        "numpy.ndarray\n",
        "```\n",
        "\n",
        "This is expected behavior of `StandardScaler`.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  What the Values Mean\n",
        "\n",
        "Each value in `X_train` is now a **z-score**:\n",
        "\n",
        "```text\n",
        "x_scaled = (x âˆ’ mean_train) / std_train\n",
        "```\n",
        "\n",
        "So:\n",
        "\n",
        "* Values around `0` â†’ average\n",
        "* Positive values â†’ above average\n",
        "* Negative values â†’ below average\n",
        "\n",
        "This makes gradients behave nicely during training.\n",
        "\n",
        "---\n",
        "## âœ… What `X_train` Represents (Now)\n",
        "\n",
        "```python\n",
        "X_train\n",
        "```\n",
        "\n",
        "### At this point in the pipeline, `X_train` is:\n",
        "\n",
        "* âœ… **A NumPy array** (not a Pandas DataFrame anymore)\n",
        "* âœ… **Scaled / standardized**\n",
        "* âœ… **Training features only**\n",
        "* âŒ **No labels**\n",
        "* âŒ **No column names**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¢ Shape Interpretation\n",
        "\n",
        "If you check:\n",
        "\n",
        "```python\n",
        "X_train.shape\n",
        "```\n",
        "\n",
        "Youâ€™ll see something like:\n",
        "\n",
        "```text\n",
        "(455, 30)\n",
        "```\n",
        "\n",
        "Meaning:\n",
        "\n",
        "* **455 samples** (80% of 569)\n",
        "* **30 features** per sample\n",
        "\n",
        "This tells you:\n",
        "\n",
        "> Your neural network input layer must accept **30 features**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ltUMxN9q2jLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train contains the target labels for the training set\n",
        "# It was created by:\n",
        "# 1. Selecting the label column from the DataFrame\n",
        "# 2. Splitting the data into training and testing sets\n",
        "#\n",
        "# y_train is used to compute the loss during training\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "uYoHEPdsVX3P",
        "outputId": "46523af5-0a0f-436b-c181-0470c4cc48c6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528    B\n",
              "526    B\n",
              "442    B\n",
              "117    M\n",
              "308    B\n",
              "      ..\n",
              "203    M\n",
              "256    M\n",
              "340    B\n",
              "219    M\n",
              "454    B\n",
              "Name: diagnosis, Length: 455, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n",
        "\n",
        "# One label per training sample\n",
        "# Matches the number of rows in X_train\n",
        "# X_train â†’ model â†’ predictions\n",
        "# y_train â†’ loss function\n",
        "\n",
        "# The loss compares:\n",
        "# Predictions vs y_train\n",
        "# Gradients are computed to update weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjdPsuRl3VKo",
        "outputId": "e1f2e2de-b24b-4b78-dda0-8e7b5ccb26d2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455,)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ Training Labels (`y_train`)\n",
        "\n",
        "`y_train` represents the **ground-truth outputs** for the training data.\n",
        "These values tell the model what the *correct answer* is.\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ What `y_train` Is\n",
        "\n",
        "- A **1D array-like structure** (Pandas Series)\n",
        "- Contains **labels only**\n",
        "- Used **only during training**\n",
        "- Corresponds exactly to `X_train`\n",
        "\n",
        "---\n",
        "So:\n",
        "\n",
        "* `df.iloc[:, 0]` â†’ label column\n",
        "* `y_train` â†’ 80% of those labels\n",
        "\n",
        "ðŸ§  Mental Model\n",
        "\n",
        "> `X_train` = questions\n",
        "\n",
        "> `y_train` = answers\n",
        "\n",
        "**The model learns by reducing the difference between the two.**"
      ],
      "metadata": {
        "id": "0QDd8Dm73fGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding"
      ],
      "metadata": {
        "id": "7XhX--USSU5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LabelEncoder object\n",
        "# This converts categorical labels into numeric form\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on training labels and transform them\n",
        "# Example: ['M', 'B'] â†’ [1, 0]\n",
        "# IMPORTANT: fit ONLY on training labels\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "\n",
        "# Transform test labels using the SAME encoder\n",
        "# Ensures consistent label mapping\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "xleQoeKbVafX"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHQJ5QegVtdF",
        "outputId": "f4b02ac9-0e43-4306-ae4c-3fcf51f3793a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¤ Label Encoding of Target Variables\n",
        "\n",
        "Machine learning models require **numeric labels**.\n",
        "This step converts categorical class labels into numbers.\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ What Is Label Encoding?\n",
        "\n",
        "Label encoding maps each unique class to an integer.\n",
        "\n",
        "Example:\n",
        "```text\n",
        "Benign (B)     â†’ 0\n",
        "Malignant (M)  â†’ 1\n",
        "```\n",
        "\n",
        "**Resulting Data Type:**\n",
        "\n",
        "After encoding:\n",
        "\n",
        "* `y_train` $\\rightarrow$ NumPy array\n",
        "* `y_test` $\\rightarrow$ NumPy array\n",
        "*  Values are integers ($0$ or $1$)"
      ],
      "metadata": {
        "id": "2Gsn915Q4k4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy arrays to PyTorch tensors"
      ],
      "metadata": {
        "id": "oZ4_HRZcSZwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "# This is required before feeding data into a PyTorch model\n",
        "\n",
        "# Training features â†’ PyTorch tensor\n",
        "X_train_tensor = torch.from_numpy(X_train)\n",
        "\n",
        "# Testing features â†’ PyTorch tensor\n",
        "X_test_tensor = torch.from_numpy(X_test)\n",
        "\n",
        "# Training labels â†’ PyTorch tensor\n",
        "y_train_tensor = torch.from_numpy(y_train)\n",
        "\n",
        "# Testing labels â†’ PyTorch tensor\n",
        "y_test_tensor = torch.from_numpy(y_test)\n"
      ],
      "metadata": {
        "id": "CHvyHOq9VuTE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Converting NumPy Arrays to PyTorch Tensors\n",
        "\n",
        "PyTorch models operate on **tensors**, not NumPy arrays.\n",
        "This step converts all processed data into PyTorch-compatible format.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DkRFQzEH7-K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the training feature tensor\n",
        "# Format: (number_of_samples, number_of_features)\n",
        "print(X_train_tensor.shape)\n",
        "\n",
        "# Check the shape of the training label tensor\n",
        "# Format: (number_of_samples,)\n",
        "print(y_train_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRGQrGrWWQNN",
        "outputId": "aa44a489-52ec-4764-a978-253c08d863cf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([455, 30])\n",
            "torch.Size([455])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why These Shapes Must Match\n",
        "\n",
        "Each row in `X_train_tensor` must correspond to exactly one label in `y_train_tensor`.\n",
        "\n",
        "`X_train_tensor[i] â†” y_train_tensor[i]`\n",
        "\n",
        "\n",
        "If this alignment breaks:\n",
        "* Loss computation fails\n",
        "* Training becomes incorrect or crashes"
      ],
      "metadata": {
        "id": "TopO1ntO8wX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the model"
      ],
      "metadata": {
        "id": "qv0fhQa1Sfx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN():\n",
        "\n",
        "    def __init__(self, X):\n",
        "        \"\"\"\n",
        "        Constructor for the neural network.\n",
        "        Initializes weights and bias.\n",
        "\n",
        "        X: input feature tensor (used only to infer input dimension)\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize weights randomly based on the number of features (X.shape[1]).\n",
        "        # Each feature gets one weight  (num_features, 1)\n",
        "        # requires_grad=True tells PyTorch to track operations on this tensor\n",
        "        # so it can calculate gradients later (for backpropagation).\n",
        "        self.weights = torch.rand(\n",
        "            X.shape[1],  # number of input features\n",
        "            1,\n",
        "            dtype=torch.float64,\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "        # Initialize bias to zero as a single scalar. This acts as the intercept.\n",
        "        self.bias = torch.zeros(\n",
        "            1,\n",
        "            dtype=torch.float64,\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "        Computes predictions from input features.\n",
        "        Math: y_pred = sigmoid(X * weights + bias)\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. Linear Step: Matrix multiplication (X @ weights) + bias\n",
        "        # z represents the \"logits\" or raw scores before activation.\n",
        "        z = torch.matmul(X, self.weights) + self.bias\n",
        "\n",
        "        # 2. Activation Step: Apply the Sigmoid function.\n",
        "        # This squashes the output between 0 and 1 (interpretable as probability).\n",
        "        # Apply sigmoid activation to convert logits to probabilities\n",
        "        y_pred = torch.sigmoid(z)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def loss_function(self, y_pred, y):\n",
        "        \"\"\"\n",
        "        Calculate Binary Cross-Entropy loss function.\n",
        "        This measures how well the predicted probabilities match the actual labels.\n",
        "        y_pred: predicted probabilities\n",
        "        y: true labels\n",
        "        \"\"\"\n",
        "\n",
        "        # Small value to prevent log(0) which causes -inf\n",
        "        # Clamp predictions to prevent 'inf' errors.\n",
        "        # log(0) is undefined (-infinity), so we force values to be\n",
        "        # slightly larger than 0 and slightly smaller than 1.\n",
        "        epsilon = 1e-7\n",
        "\n",
        "        # Clamp predictions to (epsilon, 1 - epsilon)\n",
        "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
        "\n",
        "        # Calculate the Negative Log Likelihood (BCE Formula):\n",
        "        # Loss = -1/N * sum( y*log(y_pred) + (1-y)*log(1-y_pred) )\n",
        "        loss = -(\n",
        "            y * torch.log(y_pred) +\n",
        "            (1 - y) * torch.log(1 - y_pred)\n",
        "        ).mean()\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "tNrloSpuSkwk"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Detailed Breakdown\n",
        "\n",
        "#### ðŸ§  A Simple Neural Network (From Scratch)\n",
        "\n",
        "This class implements a **single-layer neural network** for binary classification.\n",
        "Mathematically, this is equivalent to **logistic regression**.\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Model Structure\n",
        "\n",
        "The model consists of:\n",
        "- A linear layer\n",
        "- A sigmoid activation\n",
        "- A binary cross-entropy loss\n",
        "\n",
        "```text\n",
        "X â†’ (XW + b) â†’ sigmoid â†’ yÌ‚ â†’ BCE loss\n",
        "```\n",
        "\n",
        "#### A. `__init__`: Setting the Stage\n",
        "\n",
        "This method initializes the \"learnable\" parts of your network.\n",
        "\n",
        "* **`self.weights`**: You are initializing random weights. If your input `X` has 10 features (columns), you need 10 weights.\n",
        "* **`requires_grad=True`**: This is the magic switch in PyTorch. It turns on **Autograd**. It tells PyTorch, *\"Watch these variables. If I use them in a calculation, remember the steps so you can calculate the gradient (slope) later.\"* This is essential for training.\n",
        "\n",
        "#### B. `forward`: Making a Prediction\n",
        "\n",
        "This defines how data flows through the network.\n",
        "\n",
        "* **`torch.matmul(X, self.weights)`**: This is the dot product. It multiplies every input feature by its corresponding weight and sums them up.\n",
        "* **`torch.sigmoid(z)`**: A neural network without an activation function is just Linear Regression. The Sigmoid function is non-linear; it forces the output to strictly stay between  and .\n",
        "* If  is a large positive number, Sigmoid .\n",
        "* If  is a large negative number, Sigmoid .\n",
        "\n",
        "\n",
        "\n",
        "#### C. `loss_function`: Grading the Performance\n",
        "\n",
        "You are manually implementing **Binary Cross Entropy (BCE)**, which is the standard cost function for binary classification.\n",
        "\n",
        "* **The Clamping (`epsilon`)**: This is a numerical stability trick.\n",
        "* If the model predicts exactly `0` but the label is `1`, the math asks for `log(0)`, which is negative infinity. This causes the program to crash or return `NaN`.\n",
        "* `clamp` ensures the value is never exactly 0, but rather `0.0000001`.\n",
        "\n",
        "\n",
        "* **The Formula**:\n",
        "\n",
        "\n",
        "* If the actual label  is 1, only the first part of the equation matters (). We want  to be close to 1 to minimize loss.\n",
        "* If the actual label  is 0, only the second part matters ().\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sgG1xcNm-y0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Parameters"
      ],
      "metadata": {
        "id": "5gn_QAecdLJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate controls how big each parameter update step is\n",
        "# Too large â†’ unstable training\n",
        "# Too small â†’ very slow learning\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Number of times the model will see the entire training dataset\n",
        "# One epoch = one full forward + backward pass over the training data\n",
        "epochs = 25\n",
        "\n",
        "# Learning rate = how big each step is\n",
        "# Epochs = how many steps we take"
      ],
      "metadata": {
        "id": "xkfjyefSXHcv"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Pipeline"
      ],
      "metadata": {
        "id": "8IiXlBkKdONn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Create the model\n",
        "# -------------------------------\n",
        "\n",
        "# Initialize the neural network\n",
        "# X_train_tensor is passed only to determine input feature size\n",
        "model = MySimpleNN(X_train_tensor)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Training loop\n",
        "# -------------------------------\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # -------- Forward pass --------\n",
        "    # Compute model predictions for training data\n",
        "    y_pred = model.forward(X_train_tensor)\n",
        "\n",
        "    # -------- Loss computation --------\n",
        "    # Compare predictions with true labels\n",
        "    loss = model.loss_function(y_pred, y_train_tensor)\n",
        "\n",
        "    # -------- Backward pass --------\n",
        "    # Compute gradients of loss w.r.t. weights and bias\n",
        "    loss.backward()\n",
        "\n",
        "    # -------- Parameter update (Gradient Descent) --------\n",
        "    # Disable gradient tracking while updating parameters\n",
        "    with torch.no_grad():\n",
        "        model.weights -= learning_rate * model.weights.grad\n",
        "        model.bias -= learning_rate * model.bias.grad\n",
        "\n",
        "    # -------- Zero gradients --------\n",
        "    # Gradients accumulate by default, so we must reset them\n",
        "    model.weights.grad.zero_()\n",
        "    model.bias.grad.zero_()\n",
        "\n",
        "    # -------- Logging --------\n",
        "    # Print loss for monitoring training progress\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxPsNM2_XQev",
        "outputId": "54129cfb-f4fb-409a-ad59-0b510513b100"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 3.6075409078505487\n",
            "Epoch: 2, Loss: 3.479149891634001\n",
            "Epoch: 3, Loss: 3.339358523495705\n",
            "Epoch: 4, Loss: 3.198969996853641\n",
            "Epoch: 5, Loss: 3.0556455601320143\n",
            "Epoch: 6, Loss: 2.907397226325239\n",
            "Epoch: 7, Loss: 2.743784816742959\n",
            "Epoch: 8, Loss: 2.5797988405603918\n",
            "Epoch: 9, Loss: 2.4136810626776803\n",
            "Epoch: 10, Loss: 2.247786207276684\n",
            "Epoch: 11, Loss: 2.080582097019753\n",
            "Epoch: 12, Loss: 1.9129719899687871\n",
            "Epoch: 13, Loss: 1.7497833316498423\n",
            "Epoch: 14, Loss: 1.5967493688579615\n",
            "Epoch: 15, Loss: 1.4552639756889039\n",
            "Epoch: 16, Loss: 1.3225403526205357\n",
            "Epoch: 17, Loss: 1.205321156552129\n",
            "Epoch: 18, Loss: 1.10483123180394\n",
            "Epoch: 19, Loss: 1.021677641881896\n",
            "Epoch: 20, Loss: 0.9555485719621205\n",
            "Epoch: 21, Loss: 0.9050139750249961\n",
            "Epoch: 22, Loss: 0.8676429056209236\n",
            "Epoch: 23, Loss: 0.8404881640640138\n",
            "Epoch: 24, Loss: 0.8206826196522852\n",
            "Epoch: 25, Loss: 0.8058568434316598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ” Training Loop: Manual Gradient Descent with Autograd\n",
        "\n",
        "This training loop implements **end-to-end learning** for a simple neural network\n",
        "using PyTorchâ€™s automatic differentiation.\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Model Creation\n",
        "\n",
        "```python\n",
        "model = MySimpleNN(X_train_tensor)\n",
        "````\n",
        "\n",
        "* Initializes weights and bias\n",
        "* Input size is inferred from `X_train_tensor.shape[1]`\n",
        "* Parameters have `requires_grad=True`\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ Epoch Loop\n",
        "\n",
        "```python\n",
        "for epoch in range(epochs):\n",
        "```\n",
        "\n",
        "An **epoch** is one complete pass through the training dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ Forward Pass\n",
        "\n",
        "```python\n",
        "y_pred = model.forward(X_train_tensor)\n",
        "```\n",
        "\n",
        "Computes predictions using:\n",
        "\n",
        "```text\n",
        "z = XW + b\n",
        "yÌ‚ = sigmoid(z)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ Loss Computation\n",
        "\n",
        "```python\n",
        "loss = model.loss_function(y_pred, y_train_tensor)\n",
        "```\n",
        "\n",
        "* Uses Binary Cross-Entropy (BCE)\n",
        "* Measures how wrong predictions are\n",
        "* Returns a **scalar loss** (required for `.backward()`)\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ Backward Pass\n",
        "\n",
        "```python\n",
        "loss.backward()\n",
        "```\n",
        "\n",
        "Autograd:\n",
        "\n",
        "* Traverses the computation graph backward\n",
        "* Applies the chain rule\n",
        "* Computes gradients:\n",
        "\n",
        "  * `model.weights.grad`\n",
        "  * `model.bias.grad`\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ Parameter Update (Gradient Descent)\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    model.weights -= learning_rate * model.weights.grad\n",
        "    model.bias -= learning_rate * model.bias.grad\n",
        "```\n",
        "\n",
        "### Gradient Descent Rule\n",
        "\n",
        "```text\n",
        "Î¸ = Î¸ âˆ’ Î± Â· âˆ‡Î¸\n",
        "```\n",
        "\n",
        "Where:\n",
        "\n",
        "* `Î¸` = parameter\n",
        "* `Î±` = learning rate\n",
        "* `âˆ‡Î¸` = gradient\n",
        "\n",
        "`torch.no_grad()` prevents autograd from tracking updates.\n",
        "\n",
        "---\n",
        "\n",
        "## 7ï¸âƒ£ Zeroing Gradients (CRITICAL)\n",
        "\n",
        "```python\n",
        "model.weights.grad.zero_()\n",
        "model.bias.grad.zero_()\n",
        "```\n",
        "\n",
        "Why?\n",
        "\n",
        "* Gradients **accumulate by default**\n",
        "* Not clearing them causes incorrect updates\n",
        "\n",
        "Equivalent to:\n",
        "\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 8ï¸âƒ£ Monitoring Training\n",
        "\n",
        "```python\n",
        "print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")\n",
        "```\n",
        "\n",
        "* `loss.item()` converts tensor â†’ Python float\n",
        "* Loss should **decrease over epochs**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Mental Model\n",
        "\n",
        "> **Forward â†’ Loss â†’ Backward â†’ Update â†’ Repeat**\n",
        "\n",
        "This loop is the heart of *all* neural network training.\n",
        "\n",
        "---\n",
        "\n",
        "## 9ï¸âƒ£ How This Maps to Real PyTorch Code\n",
        "\n",
        "Manual version:\n",
        "\n",
        "```python\n",
        "loss.backward()\n",
        "weights -= lr * weights.grad\n",
        "weights.grad.zero_()\n",
        "```\n",
        "\n",
        "PyTorch version:\n",
        "\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… One-Line Summary\n",
        "\n",
        "> This loop trains a neural network by repeatedly computing loss, gradients, and updating parameters using gradient descent.\n",
        "\n"
      ],
      "metadata": {
        "id": "kHenvl6tAG_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the bias parameter of the model\n",
        "# This is a learnable scalar that shifts the decision boundary\n",
        "model.bias\n",
        "\n",
        "# Weights decide direction\n",
        "# Bias decides starting point\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3GSLAo5oHlk",
        "outputId": "b12f91e7-26e1-48d1-fe3a-b5039e67f95f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1514], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ Model Bias (`model.bias`)\n",
        "\n",
        "`model.bias` is a **learnable parameter** of the neural network that controls\n",
        "the **offset** of the decision boundary.\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ What Is the Bias?\n",
        "\n",
        "In the linear equation:\n",
        "\n",
        "```text\n",
        "z = XW + b\n",
        "```\n",
        "* W â†’ weights (feature importance)\n",
        "* b â†’ bias (baseline shift)\n",
        "\n",
        "The bias allows the model to make predictions even when:\n",
        "x = 0"
      ],
      "metadata": {
        "id": "tfHrZMMHAY3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "qzJuqvFHdSCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation (no training)\n",
        "\n",
        "# Disable gradient tracking to save memory and speed up computation\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Forward pass on the test data\n",
        "    # Produces predicted probabilities in range (0, 1)\n",
        "    y_pred = model.forward(X_test_tensor)\n",
        "\n",
        "    # Convert probabilities to class labels\n",
        "    # Threshold = 0.9\n",
        "    # Values > 0.9 â†’ 1, else â†’ 0\n",
        "    y_pred = (y_pred > 0.9).float()\n",
        "\n",
        "    # Compare predictions with true labels\n",
        "    # (True â†’ 1.0, False â†’ 0.0)\n",
        "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "\n",
        "    # Print accuracy as a Python float\n",
        "    print(f'Accuracy: {accuracy.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5EjQbXORCqd",
        "outputId": "068e02f1-dc79-4a49-870e-888aacaf584b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6141889691352844\n"
          ]
        }
      ]
    }
  ]
}