{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LgMnRIHSE9NjI2G1YRGSa8wIQqfSf8W8","timestamp":1766462921287}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ðŸ“˜ What Are Tensors? (Foundations for Deep Learning)\n","\n","A **tensor** is a **specialized multi-dimensional array** designed for **mathematical and computational efficiency**.   \n","\n","Tensors are the core data structure used in **PyTorch**, **TensorFlow**, and all modern deep learning frameworks.\n","\n","---\n","\n","## ðŸ”¢ Tensor Ranks (Dimensions)\n","\n","The **rank** of a tensor refers to the **number of dimensions** it has.\n","\n","---\n","\n","### 1ï¸âƒ£ Scalars ($0$D Tensor)\n","\n","- A **single number**\n","- No dimensions\n","\n","**Example use-case**\n","- Loss value after a forward pass\n","\n","```text\n","5.0\n","-3.14\n","````\n","\n","ðŸ“Œ Used to represent:\n","\n","* Loss\n","* Accuracy\n","* Single metrics\n","\n","---\n","\n","### 2ï¸âƒ£ Vectors ($1$D Tensor)\n","\n","* A list or sequence of numbers\n","\n","**Example use-case**\n","\n","* Feature vectors\n","* Word embeddings in NLP\n","\n","```text\n","[0.12, -0.84, 0.33]\n","```\n","\n","ðŸ“Œ In NLP:\n","\n","* Each word $\\rightarrow$ vector\n","* Shape: `[embedding_dim]`\n","\n","---\n","\n","### 3ï¸âƒ£ Matrices ($2$D Tensor)\n","\n","* Grid of numbers (rows Ã— columns)\n","\n","**Example use-case**\n","\n","* Grayscale images\n","* Tabular data\n","\n","```text\n","[[0, 255, 128],\n"," [34,  90, 180]]\n","```\n","\n","ðŸ“Œ Each value represents:\n","\n","* Pixel intensity (for images)\n","* Feature value (for tables)\n","\n","---\n","\n","### 4ï¸âƒ£ 3D Tensors (Colored Images)\n","\n","* Adds a **channel dimension**\n","\n","**Example use-case**\n","\n","* RGB images\n","\n","```text\n","Shape: [height, width, channels]\n","Example: [256, 256, 3]\n","```\n","\n","ðŸ“Œ Channels:\n","\n","* R â†’ Red\n","* G â†’ Green\n","* B â†’ Blue\n","\n","---\n","\n","### 5ï¸âƒ£ 4D Tensors (Batches of Images)\n","\n","* Adds **batch size** dimension\n","\n","**Example use-case**\n","\n","* Training multiple images at once\n","\n","```text\n","Shape: [batch_size, height, width, channels]\n","Example: [32, 128, 128, 3]\n","```\n","\n","ðŸ“Œ Batch dimension improves:\n","\n","* GPU utilization\n","* Training efficiency\n","\n","---\n","\n","### 6ï¸âƒ£ 5D Tensors (Video Data)\n","\n","* Adds a **time/frame dimension**\n","\n","**Example use-case**\n","\n","* Video clips\n","\n","```text\n","Shape: [batch, frames, height, width, channels]\n","Example: [10, 16, 64, 64, 3]\n","```\n","\n","ðŸ“Œ Each frame is an RGB image.\n","\n","---\n","\n","## ðŸ§  Why Are Tensors Useful?\n","\n","---\n","\n","### 1ï¸âƒ£ Mathematical Operations\n","\n","Tensors enable:\n","\n","* Addition\n","* Multiplication\n","* Dot products\n","* Matrix multiplication\n","\n","These operations form the backbone of:\n","\n","* Neural networks\n","* Backpropagation\n","* Optimization\n","\n","---\n","\n","### 2ï¸âƒ£ Representation of Real-World Data\n","\n","| Data Type | Tensor Representation |\n","| --------- | --------------------- |\n","| Image     | 3D / 4D tensor        |\n","| Text      | 2D / 3D tensor        |\n","| Audio     | 1D / 2D tensor        |\n","| Video     | 5D tensor             |\n","\n","ðŸ“Œ Everything becomes **numbers + shape**.\n","\n","---\n","\n","### 3ï¸âƒ£ Efficient Computation\n","\n","Tensors are:\n","\n","* Optimized for **parallel computation**\n","* Executed efficiently on **GPUs & TPUs**\n","\n","This makes large-scale deep learning feasible.\n","\n","---\n","\n","## ðŸ§  Where Are Tensors Used in Deep Learning?\n","\n","---\n","\n","### 1ï¸âƒ£ Data Storage\n","\n","* Holds training inputs (e.g., batches of images).\n","\n","---\n","\n","### 2ï¸âƒ£ Model Parameters\n","\n","Stores learnable weights ($W$) and biases ($b$)\n","\n","---\n","\n","### 3ï¸âƒ£ Matrix Operations\n","\n","* Linear layers\n","* Attention mechanisms\n","* Convolutions\n","\n","---\n","\n","### 4ï¸âƒ£ Training Process\n","\n","* Forward pass â†’ Data flows through the network as tensors or tensors flow through layers\n","\n","* Backward pass â†’ Gradients are calculated and stored as tensors to update the model.\n","\n","---\n","\n","## ðŸ”‘ Core Mental Model\n","\n","> **Everything in deep learning is a tensor.**\n","\n","> Data â†’ Tensor\n","\n","> Model â†’ Tensors\n","\n","> Gradients â†’ Tensors\n","\n","If you understand tensors, you understand deep learning.\n","\n","---\n","\n","## âœ… One-Line Summary\n","\n","> **Tensor = numbers + shape + meaning**\n"],"metadata":{"id":"dmqRsIsixbkL"}},{"cell_type":"code","source":["# 1. Import the PyTorch library\n","# PyTorch is the primary framework for Deep Learning (preferred over TensorFlow in research).\n","import torch\n","\n","# 2. Check the Software Version\n","# It is crucial to check this to ensure compatibility with other libraries\n","# (like torchvision or torchaudio) and your specific CUDA version.\n","print(torch.__version__)\n","\n","# 3. Check for Hardware Acceleration (CUDA)\n","# torch.cuda.is_available() returns True if:\n","#   a) You have an NVIDIA GPU.\n","#   b) The NVIDIA drivers are installed correctly.\n","#   c) The CUDA toolkit matching your PyTorch version is visible.\n","if torch.cuda.is_available():\n","    print(\"GPU is available!\")\n","\n","    # 4. Get the Hardware Name\n","    # .get_device_name(0) returns the specific name of your graphics card (e.g., \"NVIDIA GeForce RTX 3060\").\n","    # The index (0) refers to the FIRST GPU found. If you had two GPUs, the second would be index (1).\n","    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","else:\n","    # 5. Fallback\n","    # If False, PyTorch will run on the CPU (much slower for training neural networks).\n","    print(\"GPU not available. Using CPU.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZ5xDHqrZtuu","executionInfo":{"status":"ok","timestamp":1766553753598,"user_tz":-330,"elapsed":4419,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"4cafe307-ee5a-4449-91d8-e81067708354"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.0+cu126\n","GPU is available!\n","Using GPU: Tesla T4\n"]}]},{"cell_type":"markdown","source":["Key Concepts:\n","\n","1. CUDA (Compute Unified Device Architecture): This is NVIDIA's parallel computing platform. Deep Learning relies heavily on matrix multiplication, which GPUs (with thousands of tiny cores) can do much faster than CPUs (which have fewer, stronger cores).\n","\n","2. The Index (0): In multi-GPU setups (common in production or cloud training), you have to specify which GPU you want to query or use. Index 0 is always the default/primary card."],"metadata":{"id":"QE4pFbNWZ2Tc"}},{"cell_type":"markdown","source":["# Creating a Tensor"],"metadata":{"id":"BFcs4wpz4wlA"}},{"cell_type":"code","source":["# 1. Using empty\n","# Creates a tensor of size 2x3 without initializing data.\n","# The values will be whatever \"garbage\" memory was already at that address.\n","# It is very fast because it skips the step of writing zeros or ones.\n","a = torch.empty(2,3)"],"metadata":{"id":"AYzOQK7n4nNq","executionInfo":{"status":"ok","timestamp":1766553753636,"user_tz":-330,"elapsed":36,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 2. Check type\n","# Returns the Python type of the object, which is <class 'torch.Tensor'>.\n","# To check the data type OF the numbers inside (e.g., float32), use a.dtype.\n","type(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSOoTAZY5FR1","executionInfo":{"status":"ok","timestamp":1766553753647,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"37105b65-14e7-4d72-d181-66e9f64b8499"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# 3. Using zeros\n","# Creates a 2x3 tensor filled entirely with 0s.\n","# Useful for initializing weights in some specific neural network architectures (like bias).\n","torch.zeros(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LxVQPOVN47Dt","executionInfo":{"status":"ok","timestamp":1766553753686,"user_tz":-330,"elapsed":39,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"d959e41e-da59-4899-ee3a-2103bb704e9b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 4. Using ones\n","# Creates a 2x3 tensor filled entirely with 1s.\n","torch.ones(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3-KPOlX48mT","executionInfo":{"status":"ok","timestamp":1766553753706,"user_tz":-330,"elapsed":19,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"5dbcba03-a619-4059-a898-9155ce7c41f9"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# 5. Using rand\n","# Creates a 2x3 tensor with random numbers from a Uniform Distribution\n","# between 0 and 1 (interval [0, 1)).\n","torch.rand(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_j_mRGK4-DA","executionInfo":{"status":"ok","timestamp":1766553753747,"user_tz":-330,"elapsed":40,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"073d8b72-8003-4235-bddb-1839205d1438"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0543, 0.7557, 0.1464],\n","        [0.7087, 0.2508, 0.6681]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# 6. Use of seed (Demonstration of non-reproducibility)\n","# Calling rand again WITHOUT resetting the seed will generate DIFFERENT numbers.\n","torch.rand(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCAf-HRw5SiA","executionInfo":{"status":"ok","timestamp":1766553753758,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"cf777e8e-93b4-4870-b0a8-b9d38c2e9ba1"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1168, 0.3304, 0.5598],\n","        [0.8645, 0.0376, 0.9821]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# 7. manual_seed\n","# Sets the \"seed\" for the random number generator.\n","# A seed is a starting point; if you start from the same point, the sequence of\n","# \"random\" numbers is identical.\n","torch.manual_seed(100)\n","print(torch.rand(2,3)) # Prints Sequence A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvAqsoFG5UMr","executionInfo":{"status":"ok","timestamp":1766553753765,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"81140bef-37d8-478f-e545-fabc38de4ad7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1117, 0.8158, 0.2626],\n","        [0.4839, 0.6765, 0.7539]])\n"]}]},{"cell_type":"code","source":["# Resetting the seed to the SAME value (100) ensures the next call produces\n","# exactly Sequence A again. This is crucial for debugging ML models.\n","torch.manual_seed(100)\n","print(torch.rand(2,3)) # Prints Sequence A again"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNETtp8Ha1mh","executionInfo":{"status":"ok","timestamp":1766553753769,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"b918335c-3091-4932-da72-a056815f1f1c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1117, 0.8158, 0.2626],\n","        [0.4839, 0.6765, 0.7539]])\n"]}]},{"cell_type":"code","source":["torch.manual_seed(100)\n","torch.rand(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96Akgtgs5Ulp","executionInfo":{"status":"ok","timestamp":1766553753774,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"9144f2d1-e925-4542-ceae-156ecdb3bb44"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1117, 0.8158, 0.2626],\n","        [0.4839, 0.6765, 0.7539]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 8. Using tensor\n","# Creates a tensor from a standard Python list.\n","# PyTorch infers the data type (usually int64 or float32) based on the input.\n","torch.tensor([[1,2,3],[4,5,6]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YLLqcGB4_4J","executionInfo":{"status":"ok","timestamp":1766553753778,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ad122064-f734-4010-bd2c-febea909959a"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3],\n","        [4, 5, 6]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":[" ---\n"," ## Other ways to create tensors\n"," ---"],"metadata":{"id":"9ZSALt3oa9LG"}},{"cell_type":"code","source":["# 9. arange (Array Range)\n","# Creates a 1D tensor starting at start (0), up to but NOT including end (10),\n","# stepping by step (2).\n","# Output: [0, 2, 4, 6, 8]\n","print(\"using arange ->\", torch.arange(0,10,2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLj35yxr6Qgv","executionInfo":{"status":"ok","timestamp":1766553753834,"user_tz":-330,"elapsed":55,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"087cdf77-f623-4aee-dc59-97b821190e74"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["using arange -> tensor([0, 2, 4, 6, 8])\n"]}]},{"cell_type":"code","source":["# 10. linspace (Linear Space)\n","# Creates a 1D tensor starting at start (0) and ending EXACTLY at end (10).\n","# The third argument is the NUMBER OF STEPS (points) to generate, not the step size.\n","# Useful for creating graphs or time-series grids.\n","print(\"using linspace ->\", torch.linspace(0,10,10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ql7qhf-bN4A","executionInfo":{"status":"ok","timestamp":1766553753835,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"5a2684bf-dfd7-48e2-a073-f15c4c39b107"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["using linspace -> tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n","         8.8889, 10.0000])\n"]}]},{"cell_type":"code","source":["# 11. using eye (Identity Matrix)\n","# Creates a 2D square tensor (5x5) with 1s on the diagonal and 0s elsewhere.\n","# \"Eye\" sounds like \"I\" for Identity. Crucial in Linear Algebra.\n","print(\"using eye ->\", torch.eye(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODA_mxk7bs3N","executionInfo":{"status":"ok","timestamp":1766553753835,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"255a5683-d164-4743-c110-3f384e55cc30"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["using eye -> tensor([[1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1.]])\n"]}]},{"cell_type":"code","source":["# 12. using full\n","# Creates a tensor of specific shape (3x3) filled entirely with a specific value (5).\n","# Equivalent to: torch.ones(3,3) * 5\n","print(\"using full ->\", torch.full((3, 3), 5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2ICB9dDbu6l","executionInfo":{"status":"ok","timestamp":1766553753840,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"d8f6ab11-ef6c-428b-ea90-e864c5938983"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["using full -> tensor([[5, 5, 5],\n","        [5, 5, 5],\n","        [5, 5, 5]])\n"]}]},{"cell_type":"markdown","source":["\n","---\n","\n","#### 1ï¸âƒ£ `torch.empty()`\n","\n","```python\n","torch.empty(2, 3)\n","````\n","\n","##### What it does:\n","\n","* Allocates memory for a tensor **without initializing values**\n","* Contents are **random garbage values**\n","\n","##### When to use:\n","\n","* When performance matters and values will be overwritten\n","* Common in low-level or optimized code\n","\n","âš ï¸ **Danger:** Never use `empty()` if you expect meaningful values!\n","\n","---\n","\n","#### 2ï¸âƒ£ `torch.zeros()` and `torch.ones()`\n","\n","```python\n","torch.zeros(2, 3)\n","torch.ones(2, 3)\n","```\n","\n","##### What they do:\n","\n","* Create tensors filled with `0`s or `1`s\n","\n","##### When to use:\n","\n","* Initializing weights, biases, masks\n","* Safe and predictable defaults\n","\n","---\n","\n","#### 3ï¸âƒ£ `torch.rand()`\n","\n","```python\n","torch.rand(2, 3)\n","```\n","\n","##### What it does:\n","\n","* Generates random numbers from **Uniform(0, 1)**\n","\n","##### Use cases:\n","\n","* Weight initialization\n","* Data augmentation\n","* Random sampling\n","\n","---\n","\n","#### 4ï¸âƒ£ Reproducibility with `torch.manual_seed()`\n","\n","```python\n","torch.manual_seed(100)\n","torch.rand(2, 3)\n","```\n","\n","##### Why this matters:\n","\n","* Same seed â†’ same random numbers\n","* Critical for:\n","\n","  * Debugging\n","  * Experiments\n","  * Research reproducibility\n","\n","> Always set a seed when training models you want to compare.\n","\n","---\n","\n","#### 5ï¸âƒ£ `torch.tensor()`\n","\n","```python\n","torch.tensor([[1, 2, 3],\n","              [4, 5, 6]])\n","```\n","\n","##### What it does:\n","\n","* Converts Python lists or NumPy arrays into tensors\n","\n","##### Use cases:\n","\n","* Loading small datasets\n","* Creating fixed reference tensors\n","\n","---\n","\n","#### 6ï¸âƒ£ `torch.arange()`\n","\n","```python\n","torch.arange(0, 10, 2)\n","```\n","\n","##### Output:\n","\n","```\n","tensor([0, 2, 4, 6, 8])\n","```\n","\n","##### When to use:\n","\n","* Indexing\n","* Loop counters\n","* Discrete sequences\n","\n","---\n","\n","#### 7ï¸âƒ£ `torch.linspace()`\n","\n","```python\n","torch.linspace(0, 10, 10)\n","```\n","\n","##### Key difference from `arange()`:\n","\n","* Specifies **number of points**, not step size\n","\n","##### Common use:\n","\n","* Plotting\n","* Continuous ranges\n","* Numerical methods\n","\n","---\n","\n","#### 8ï¸âƒ£ `torch.eye()`\n","\n","```python\n","torch.eye(5)\n","```\n","\n","##### What it creates:\n","\n","* Identity matrix\n","\n","##### Why important:\n","\n","* Linear algebra\n","* Neural network layers\n","* Matrix transformations\n","\n","---\n","\n","#### 9ï¸âƒ£ `torch.full()`\n","\n","```python\n","torch.full((3, 3), 5)\n","```\n","\n","##### What it does:\n","\n","* Creates a tensor with the same constant value everywhere\n","\n","##### Use cases:\n","\n","* Padding\n","* Masks\n","* Custom initialization\n","\n","---\n","\n","## ðŸ§  Mental Model\n","\n","> **A tensor is just a box of numbers + shape + datatype + device**\n","\n"],"metadata":{"id":"ozwrVfi_cGF-"}},{"cell_type":"markdown","source":["# Tensor Shapes"],"metadata":{"id":"0ejaUWSkinz0"}},{"cell_type":"code","source":["# 1. Create a base tensor\n","# We create a 2D tensor (a matrix) with 2 rows and 3 columns.\n","x = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])"],"metadata":{"id":"HDrr5mQ86R4K","executionInfo":{"status":"ok","timestamp":1766553753842,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 2. Inspect the tensor\n","# Output will display the data:\n","# tensor([[1, 2, 3],\n","#         [4, 5, 6]])\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGZhrLablBq-","executionInfo":{"status":"ok","timestamp":1766553753847,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"b7dce0cb-fa53-4d40-ebba-5e0bafd8085a"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3],\n","        [4, 5, 6]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# 3. Check the Shape\n","# Returns torch.Size([2, 3]).\n","# This tells us the dimensions: 2 rows (dimension 0) and 3 columns (dimension 1).\n","# In Deep Learning, checking .shape is the #1 way to debug errors.\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rt61iIxwkew9","executionInfo":{"status":"ok","timestamp":1766553753852,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"7b06d105-a3e6-48dc-9d8b-f5fcae23db76"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":[" ---\n"," ### The `\"_like\"` Functions\n"," ---"],"metadata":{"id":"eURoa8bEkjm-"}},{"cell_type":"code","source":["# These functions are shortcuts. Instead of manually specifying (2, 3),\n","# you just say \"make me a new tensor with the same shape as x\""],"metadata":{"id":"NEQW9QhmlKXA","executionInfo":{"status":"ok","timestamp":1766553753874,"user_tz":-330,"elapsed":23,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 4. empty_like\n","# Creates a new 2x3 tensor with uninitialized data (\"garbage values\").\n","# It looks at 'x', sees it is 2x3, and allocates that much memory.\n","# Note: It inherits the device (CPU/GPU) of x, but the data is random noise.\n","torch.empty_like(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_FSd1Rvkp01","executionInfo":{"status":"ok","timestamp":1766553753884,"user_tz":-330,"elapsed":32,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"fb553e64-b788-4a6d-baaa-4c44a38a3202"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[              0,      1102781216,      1074268576],\n","        [139242769659808,               0,               0]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# 5. zeros_like\n","# Creates a new 2x3 tensor filled entirely with 0s.\n","# Highly useful for initializing \"mask\" tensors or accumulators.\n","torch.zeros_like(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMgWa_hyktDl","executionInfo":{"status":"ok","timestamp":1766553753911,"user_tz":-330,"elapsed":27,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"8863dd9f-6a70-4ecc-ba47-7524a33f1747"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0, 0],\n","        [0, 0, 0]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# 6. ones_like\n","# Creates a new 2x3 tensor filled entirely with 1s.\n","torch.ones_like(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4k0k4WPZkuwG","executionInfo":{"status":"ok","timestamp":1766553753916,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"0ff466e4-b5e5-4781-f08e-e16a5307f943"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1, 1],\n","        [1, 1, 1]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# 7. rand_like\n","# Creates a new 2x3 tensor filled with random numbers from 0 to 1.\n","# CRITICAL NOTE: 'rand' requires floating point numbers.\n","# Our original 'x' contains integers (1, 2, 3...), so its type is likely Long/Int64.\n","# Random numbers are floats (0.45, 0.99), so we MUST specify dtype=torch.float32\n","# otherwise PyTorch might try to cast 0.5 to an integer (which becomes 0) or throw an error.\n","torch.rand_like(x, dtype=torch.float32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7SM7MATkwgE","executionInfo":{"status":"ok","timestamp":1766553753921,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ac138b96-1127-4410-b123-067173017d04"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2627, 0.0428, 0.2080],\n","        [0.1180, 0.1217, 0.7356]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":[">The function torch.rand (uniform distribution) inherently generates floating-point numbers. If you try torch.rand_like(x) where x is an integer tensor, PyTorch sees a conflict: \"You want a tensor like x (Integers) but you want random probabilities (Floats).\" Explicitly passing dtype=torch.float32 resolves this ambiguity."],"metadata":{"id":"wZjwy0bwmE3i"}},{"cell_type":"markdown","source":["\n","Understanding tensor shapes and `_like()` functions is essential for:\n","- Weight initialization\n","- Mask creation\n","- Broadcasting\n","- Writing bug-free deep learning code\n","\n","---\n","\n","#### 1ï¸âƒ£ Tensor Shape\n","\n","```python\n","x = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])\n","x.shape\n","````\n","\n","##### Output\n","\n","```text\n","torch.Size([2, 3])\n","```\n","\n","##### Interpretation\n","\n","* `2` â†’ number of rows\n","* `3` â†’ number of columns\n","\n","> **Mental model:**\n","> Shape tells you **how data is arranged in memory**, not what the values mean.\n","\n","---\n","\n","#### 2ï¸âƒ£ Why Shape Matters\n","\n","Almost all PyTorch errors come from:\n","\n","* Shape mismatch\n","* Unexpected broadcasting\n","* Wrong batch dimensions\n","\n","Example:\n","\n","```text\n","RuntimeError: size mismatch\n","```\n","\n","If you understand `.shape`, you avoid 80% of bugs.\n","\n","---\n","\n","#### 3ï¸âƒ£ `_like()` Functions â€” The Core Idea\n","\n","##### Key Principle\n","\n","> `_like()` functions **copy the shape (and usually dtype)** of an existing tensor.\n","\n","In real deep learning code (like Transformers or CNNs), tensor shapes change dynamically based on the batch size or the length of a sentence. You often don't know the shape ahead of time.\n","\n","1. Hard-coding: torch.zeros(32, 10) requires you to know the batch size is 32. If you change your batch size to 64 later, this line breaks.\n","\n","2. Dynamic (Best Practice): torch.zeros_like(input_batch) automatically adapts. If input_batch is 64, the zeros will be 64. If it's 32, the zeros will be 32. This makes your code robust and reusable.\n","\n","They answer:\n","\n","> â€œGive me a tensor shaped exactly like this one.â€\n","\n","---\n","\n","##### 4ï¸âƒ£ `torch.empty_like()`\n","\n","```python\n","torch.empty_like(x)\n","```\n","\n","##### What it does:\n","\n","* Same shape as `x`\n","* Values are **uninitialized**\n","\n","##### When to use:\n","\n","* Performance-critical code\n","* Values will be overwritten immediately\n","\n","âš ï¸ Never assume values are zero!\n","\n","---\n","\n","#### 5ï¸âƒ£ `torch.zeros_like()`\n","\n","```python\n","torch.zeros_like(x)\n","```\n","\n","##### What it does:\n","\n","* Same shape as `x`\n","* All values = `0`\n","\n","##### Common use cases:\n","\n","* Initializing gradients\n","* Creating masks\n","* Resetting buffers\n","\n","---\n","\n","#### 6ï¸âƒ£ `torch.ones_like()`\n","\n","```python\n","torch.ones_like(x)\n","```\n","\n","##### What it does:\n","\n","* Same shape as `x`\n","* All values = `1`\n","\n","##### Use cases:\n","\n","* Bias initialization\n","* Scaling factors\n","* Boolean masks (after type conversion)\n","\n","---\n","\n","#### 7ï¸âƒ£ `torch.rand_like()`\n","\n","```python\n","torch.rand_like(x, dtype=torch.float32)\n","```\n","\n","##### What it does:\n","\n","* Same shape as `x`\n","* Random values from **Uniform(0, 1)**\n","\n","##### Why specify `dtype`?\n","\n","* Original tensor `x` is integer\n","* Random numbers must be floats\n","* Prevents silent bugs\n","\n","---\n","\n","#### 8ï¸âƒ£ Shape + dtype Summary Table\n","\n","| Function     | Shape         | Values  | Initialized |\n","| ------------ | ------------- | ------- | ----------- |\n","| `empty_like` | Same as input | Garbage | âŒ           |\n","| `zeros_like` | Same as input | All 0   | âœ…           |\n","| `ones_like`  | Same as input | All 1   | âœ…           |\n","| `rand_like`  | Same as input | Random  | âœ…           |\n","\n","---\n","\n","##### ðŸ§  Core Mental Model\n","\n","> `_like()` functions = **shape cloning tools**\n","\n","Instead of manually remembering shapes:\n","\n","```python\n","torch.zeros(2, 3)  # âŒ brittle\n","```\n","\n","Do this:\n","\n","```python\n","torch.zeros_like(x)  # âœ… safe and scalable\n","```\n","\n","---\n","\n","#### ðŸš€ Why This Matters in Deep Learning\n","\n","* Neural network layers expect **exact shapes**\n","* `_like()` prevents:\n","\n","  * Hard-coded dimensions\n","  * Shape mismatch bugs\n","  * Fragile refactors\n","\n","If your code survives changing batch size â†’ you did it right.\n","\n","\n"],"metadata":{"id":"FV3yWKe5lMb-"}},{"cell_type":"markdown","source":["## Tensor Data Types"],"metadata":{"id":"nYM1fR5BmxIf"}},{"cell_type":"code","source":["# Assume x is a tensor we created earlier\n","x = torch.tensor([1, 2, 3])\n","\n","# 1. Find Data Type\n","# .dtype is an attribute (not a method, so no parenthesis).\n","# It tells you how the numbers are stored in memory (e.g., torch.int64, torch.float32).\n","# PyTorch defaults to int64 (Long) for integers and float32 for decimals.\n","x.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jy-rBsKSliAe","executionInfo":{"status":"ok","timestamp":1766553753929,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f2783c53-5bbc-4a12-fe3d-ad1bea797a83"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.int64"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# 2. Assign Data Type during creation\n","# Here we pass a list of FLOATS [1.0, 2.0, 3.0] but force the type to INT32.\n","# PyTorch will truncate the decimal part. This saves memory (32-bit vs 64-bit)\n","# but loses precision.\n","torch.tensor([1.0, 2.0, 3.0], dtype=torch.int32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6T2gmrujnaMA","executionInfo":{"status":"ok","timestamp":1766553753934,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"566a2469-a203-41b2-f4e8-deef0acb357c"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3], dtype=torch.int32)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# Here we pass a list of INTEGERS [1, 2, 3] but force the type to FLOAT64 (Double).\n","# This is useful when you need extreme numerical precision, though it is\n","# slower and takes up 2x memory compared to float32.\n","torch.tensor([1, 2, 3], dtype=torch.float64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZ8lMLsInffd","executionInfo":{"status":"ok","timestamp":1766553753938,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"098ce4f0-1830-4a52-f9f4-9869a8851ba0"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3.], dtype=torch.float64)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# 3. Using .to() for casting\n","# This is the most common way to convert an EXISTING tensor to a new type.\n","# It returns a NEW tensor with the requested type.\n","# Note: .to() is also used to move tensors between CPU and GPU (e.g., .to(\"cuda\")).\n","x = x.to(torch.float32)"],"metadata":{"id":"WTAB-h_ing07","executionInfo":{"status":"ok","timestamp":1766553753940,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### The `.to()` Method: The Swiss Army Knife\n","The .to() method is one of the most important commands in PyTorch because it handles two things simultaneously:\n","\n","1. Type Conversion: x.to(torch.float32)\n","2. Device Movement: x.to('cuda')\n","\n","You can even do both at once:\n","\n","```\n","# Move to GPU AND convert to float16 (half precision) in one step\n","x = x.to(device='cuda', dtype=torch.float16)\n","```"],"metadata":{"id":"p6Sc2KHKnSAu"}},{"cell_type":"markdown","source":["| **Data Type**             | **Dtype**         | **Description**                                                                                                                                                                |\n","|---------------------------|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| **32-bit Floating Point** | `torch.float32`   | Standard floating-point type used for most deep learning tasks. Provides a balance between precision and memory usage.                                                         |\n","| **64-bit Floating Point** | `torch.float64`   | Double-precision floating point. Useful for high-precision numerical tasks but uses more memory.                                                                               |\n","| **16-bit Floating Point** | `torch.float16`   | Half-precision floating point. Commonly used in mixed-precision training to reduce memory and computational overhead on modern GPUs.                                            |\n","| **BFloat16**              | `torch.bfloat16`  | Brain floating-point format with reduced precision compared to `float16`. Used in mixed-precision training, especially on TPUs.                                                |\n","| **8-bit Floating Point**  | `torch.float8`    | Ultra-low-precision floating point. Used for experimental applications and extreme memory-constrained environments (less common).                                               |\n","| **8-bit Integer**         | `torch.int8`      | 8-bit signed integer. Used for quantized models to save memory and computation in inference.                                                                                   |\n","| **16-bit Integer**        | `torch.int16`     | 16-bit signed integer. Useful for special numerical tasks requiring intermediate precision.                                                                                    |\n","| **32-bit Integer**        | `torch.int32`     | Standard signed integer type. Commonly used for indexing and general-purpose numerical tasks.                                                                                  |\n","| **64-bit Integer**        | `torch.int64`     | Long integer type. Often used for large indexing arrays or for tasks involving large numbers.                                                                                  |\n","| **8-bit Unsigned Integer**| `torch.uint8`     | 8-bit unsigned integer. Commonly used for image data (e.g., pixel values between 0 and 255).                                                                                    |\n","| **Boolean**               | `torch.bool`      | Boolean type, stores `True` or `False` values. Often used for masks in logical operations.                                                                                      |\n","| **Complex 64**            | `torch.complex64` | Complex number type with 32-bit real and 32-bit imaginary parts. Used for scientific and signal processing tasks.                                                               |\n","| **Complex 128**           | `torch.complex128`| Complex number type with 64-bit real and 64-bit imaginary parts. Offers higher precision but uses more memory.                                                                 |\n","| **Quantized Integer**     | `torch.qint8`     | Quantized signed 8-bit integer. Used in quantized models for efficient inference.                                                                                              |\n","| **Quantized Unsigned Integer** | `torch.quint8` | Quantized unsigned 8-bit integer. Often used for quantized tensors in image-related tasks.                                                                                     |\n"],"metadata":{"id":"dLm25jhknmuQ"}},{"cell_type":"markdown","source":["## Mathematical Operations (Element-wise)\n","\n","\n","PyTorch supports **vectorized mathematical operations**, meaning:\n","> The operation is applied to **every element** in the tensor automatically.\n","\n","No loops required ðŸš€"],"metadata":{"id":"baPoka3lqpEQ"}},{"cell_type":"markdown","source":["### 1. Scalar operation"],"metadata":{"id":"wre7rSdlqsOB"}},{"cell_type":"code","source":["# 1. Create a random tensor\n","# Creates a 2x2 matrix with random floats between 0 and 1.\n","x = torch.rand(2,2)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CS69nYyanqYD","executionInfo":{"status":"ok","timestamp":1766553753946,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f86b8579-46b3-496e-c2ae-2d758509b269"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.7118, 0.7876],\n","        [0.4183, 0.9014]])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# 2. Addition (Broadcasting)\n","# Adds 2 to EVERY element in the tensor.\n","# Internally, PyTorch \"broadcasts\" the scalar 2 to shape (2,2) and adds it.\n","# result[i][j] = x[i][j] + 2\n","x + 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zHXtjr_nkak","executionInfo":{"status":"ok","timestamp":1766553753974,"user_tz":-330,"elapsed":27,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"d65dd779-1799-41cf-a044-021b5a6acf9b"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.7118, 2.7876],\n","        [2.4183, 2.9014]])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# 3. Subtraction\n","# Subtracts 2 from every element.\n","x - 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMuEU82enopM","executionInfo":{"status":"ok","timestamp":1766553753987,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"8aedb839-c62a-4464-b678-7d4303840a28"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.2882, -1.2124],\n","        [-1.5817, -1.0986]])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# 4. Scalar Multiplication\n","# Multiplies every element by 3.\n","# Note: This is NOT matrix multiplication. It simply scales the values.\n","x * 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCuKnYsdnqQ8","executionInfo":{"status":"ok","timestamp":1766553754003,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"0c142e26-8474-4ae3-a27b-70cd20454c8e"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.1353, 2.3627],\n","        [1.2549, 2.7042]])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# 5. Division\n","# Divides every element by 3. Result is a float tensor.\n","x / 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4N2lNoEnrmA","executionInfo":{"status":"ok","timestamp":1766553754012,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"9bc80f9c-ebbe-4ed1-dbb3-d70b82994e90"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2373, 0.2625],\n","        [0.1394, 0.3005]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# 6. Floor (Integer) Division\n","# First scales by 100, then divides by 3, and keeps only the WHOLE number part.\n","# Example: 5.9 // 3 = 1.0 (truncates the decimal).\n","(x * 100) // 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQjcmhjcntJu","executionInfo":{"status":"ok","timestamp":1766553754017,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f161e96a-9f4d-43d8-b077-f916bc7f4836"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[23., 26.],\n","        [13., 30.]])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# 7. Modulo (Remainder)\n","# Returns the remainder after division.\n","# Useful for checking parity (even/odd) or cycling indices.\n","((x * 100) // 3) % 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6IozS6tnuzF","executionInfo":{"status":"ok","timestamp":1766553754035,"user_tz":-330,"elapsed":18,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ee8b667a-8f0c-4328-cf30-8957e2a17707"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0.],\n","        [1., 0.]])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# 8. Power / Exponentiation\n","# Squares EVERY individual element.\n","# result[i][j] = x[i][j] ^ 2\n","# Note: This is element-wise squaring, NOT matrix squaring (x @ x).\n","x**2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2-QmrNKnxBw","executionInfo":{"status":"ok","timestamp":1766553754041,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"b215d99e-4766-4284-abf3-3fd5fd49f3f4"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.5066, 0.6203],\n","        [0.1750, 0.8125]])"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["### 2. Element wise operation\n","\n","Element-wise operations apply a function to **each corresponding element** of tensors.\n","\n","> No loops. No indexing. Fully vectorized."],"metadata":{"id":"y2n84o2ZrGcY"}},{"cell_type":"code","source":["# 1. Setup Data\n","# Create two 2x3 matrices with random values between 0 and 1.\n","a = torch.rand(2,3)\n","b = torch.rand(2,3)\n","\n","print(\"Tensor A:\\n\", a)\n","print(\"Tensor B:\\n\", b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcnbNatwq1_3","executionInfo":{"status":"ok","timestamp":1766553754061,"user_tz":-330,"elapsed":20,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"25b91730-6926-49c3-b0eb-6ca6e66011a7"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor A:\n"," tensor([[0.9969, 0.7565, 0.2239],\n","        [0.3023, 0.1784, 0.8238]])\n","Tensor B:\n"," tensor([[0.5557, 0.9770, 0.4440],\n","        [0.9478, 0.7445, 0.4892]])\n"]}]},{"cell_type":"code","source":["# --- Basic Arithmetic (Element-Wise) ---\n","# In all these cases, the operation happens between a[i][j] and b[i][j].\n","# The tensors MUST have the same shape (or be broadcastable).\n","\n","# Addition: a[i] + b[i]\n","print(a + b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qye9acabrUae","executionInfo":{"status":"ok","timestamp":1766553754062,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"957693d1-a06b-4dad-8854-04b0f17ad924"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.5526, 1.7335, 0.6679],\n","        [1.2502, 0.9229, 1.3130]])\n"]}]},{"cell_type":"code","source":["# Subtraction: a[i] - b[i]\n","print(a - b)"],"metadata":{"id":"ftIq3-30rnhR","executionInfo":{"status":"ok","timestamp":1766553754127,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3664de7a-e27d-4e64-9fc0-13594559d803"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.4411, -0.2205, -0.2201],\n","        [-0.6455, -0.5661,  0.3346]])\n"]}]},{"cell_type":"code","source":["# Multiplication (Hadamard Product): a[i] * b[i]\n","# WARNING: This is NOT matrix multiplication (dot product).\n","print(a * b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5idoGXGVjq_N","executionInfo":{"status":"ok","timestamp":1766553754152,"user_tz":-330,"elapsed":23,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"60281e10-a073-4316-f52b-296247a89b06"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5540, 0.7391, 0.0994],\n","        [0.2866, 0.1328, 0.4030]])\n"]}]},{"cell_type":"code","source":["# Division: a[i] / b[i]\n","print(a / b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZjNZnRZjtHj","executionInfo":{"status":"ok","timestamp":1766553754160,"user_tz":-330,"elapsed":27,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"78d794e5-ab93-47c7-f1f6-63046d621f65"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.7938, 0.7743, 0.5042],\n","        [0.3190, 0.2397, 1.6841]])\n"]}]},{"cell_type":"code","source":["# Exponentiation/Power: a[i] raised to the power of b[i]\n","print(a ** b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUOlyc_KjuWz","executionInfo":{"status":"ok","timestamp":1766553754160,"user_tz":-330,"elapsed":23,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"aba8ab78-8bce-44c0-e5aa-afc0f4b1efb2"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9983, 0.7614, 0.5145],\n","        [0.3218, 0.2771, 0.9096]])\n"]}]},{"cell_type":"code","source":["# Modulo (Remainder): Remainder of division a[i] / b[i]\n","print(a % b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2viJ5Ylcjv5R","executionInfo":{"status":"ok","timestamp":1766553754254,"user_tz":-330,"elapsed":101,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"d0c68674-5769-4286-85d6-256c77e29cab"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4411, 0.7565, 0.2239],\n","        [0.3023, 0.1784, 0.3346]])\n"]}]},{"cell_type":"code","source":["# --- Math Functions ---\n","\n","# Create a sample tensor with integers (positive and negative)\n","c = torch.tensor([1, -2, 3, -4])"],"metadata":{"id":"QhHHkttdjxrC","executionInfo":{"status":"ok","timestamp":1766553754255,"user_tz":-330,"elapsed":72,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Absolute Value\n","# Converts all negative numbers to positive. |-2| -> 2.\n","print(torch.abs(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9ioZoU4jy7J","executionInfo":{"status":"ok","timestamp":1766553754255,"user_tz":-330,"elapsed":71,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"314a7e78-c44f-40ba-b8b3-a6e21201298e"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 4])\n"]}]},{"cell_type":"code","source":["# Negation\n","# Flips the sign of every element. 1 -> -1, -2 -> 2.\n","print(torch.neg(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyhKcR-Sj0DG","executionInfo":{"status":"ok","timestamp":1766553754255,"user_tz":-330,"elapsed":66,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"e0a4b507-f3bf-4e96-b5ee-cc975f1d7b3c"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-1,  2, -3,  4])\n"]}]},{"cell_type":"code","source":["# --- Rounding & Clamping ---\n","# I am defining 'd' here since it was missing in your snippet.\n","# We need floating point numbers to see the effects of rounding.\n","d = torch.tensor([1.1, 2.5, 2.9, 3.0])"],"metadata":{"id":"L49Psyyvj10L","executionInfo":{"status":"ok","timestamp":1766553754256,"user_tz":-330,"elapsed":58,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Round\n","# Rounds to the nearest integer.\n","# Note: PyTorch uses \"Round to Even\" for x.5 cases (2.5 -> 2, 3.5 -> 4).\n","print(torch.round(d))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqtBSMvKj3Qf","executionInfo":{"status":"ok","timestamp":1766553754256,"user_tz":-330,"elapsed":57,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"9e357388-db2f-4c67-e067-229d74915924"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 3.])\n"]}]},{"cell_type":"code","source":["# Ceiling (Ceil)\n","# Rounds UP to the nearest integer (moves towards +infinity).\n","# 1.1 -> 2.0\n","print(torch.ceil(d))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFiySexoj4xi","executionInfo":{"status":"ok","timestamp":1766553754256,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"80ffd03d-f031-44df-dcbd-4342776ebb04"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 3., 3., 3.])\n"]}]},{"cell_type":"code","source":["# Floor\n","# Rounds DOWN to the nearest integer (moves towards -infinity).\n","# 2.9 -> 2.0\n","print(torch.floor(d))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXUcO56Aj6oo","executionInfo":{"status":"ok","timestamp":1766553754267,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"9188cb36-ec45-4cf0-aa40-57c7efa8d995"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 2., 3.])\n"]}]},{"cell_type":"code","source":["# Clamp (Clip)\n","# Restricts values to be within a specific range [min, max].\n","# If x < min, replace with min.\n","# If x > max, replace with max.\n","# Example: clamp(d, min=2, max=3)\n","# 1.1 becomes 2.0 (too small)\n","# 2.5 stays 2.5 (in range)\n","# 2.9 stays 2.9 (in range)\n","# 3.0 stays 3.0 (in range)\n","print(torch.clamp(d, min=2, max=3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5bvrxO2j8UT","executionInfo":{"status":"ok","timestamp":1766553754270,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"8d8b6691-11e0-4495-b216-c255fa202ebb"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2.0000, 2.5000, 2.9000, 3.0000])\n"]}]},{"cell_type":"markdown","source":["###Key Concepts\n","1. Element-Wise OperationsAll the operators shown above $(+, -, *, /, **)$ work element-wise.\n","* If you multiply a matrix A by a matrix B using $A * B$, PyTorch multiplies $A_{11}$ by $B_{11}$, $A_{12}$ by $B_{12}$, etc.\n","* This is known as the **Hadamard Product**.\n","* **Critical Warning**: If you want actual linear algebra \"Matrix Multiplication\" (dot product), you must use `torch.matmul(x, x)` or the `@` operator `(x @ x)`.\n","2. BroadcastingThe magic that allows you to do `Matrix + Number` is called **Broadcasting**. PyTorch automatically expands the smaller tensor (the scalar $2$) to match the dimensions of the larger tensor (2x2) without actually copying the data in memory. This makes operations incredibly fast and memory-efficient."],"metadata":{"id":"0CcRaLZCzhWS"}},{"cell_type":"markdown","source":["### 3. Reduction operation\n","\n","Reduction operations **collapse a tensor** into:\n","- A scalar, or\n","- A lower-dimensional tensor\n","\n","They are fundamental for:\n","- Loss computation\n","- Metrics\n","- Decision making (argmax / argmin)\n","\n","### What is a Reduction?\n","\n","> **Reduction = many values â†’ fewer values**\n","\n","Examples:\n","- Sum all values â†’ scalar\n","- Mean per column â†’ vector\n","\n","---"],"metadata":{"id":"4vWfG_ZmsN0J"}},{"cell_type":"code","source":["# 1. Create a Tensor\n","# We generate random integers between 0 and 10, but STORE them as floats (float32).\n","# Why float32? Functions like mean(), std(), and var() only work on floating-point numbers.\n","# If you used integers (default for randint), those lines would throw an error.\n","e = torch.randint(size=(2,3), low=0, high=10, dtype=torch.float32)\n","# Example State:\n","# [[1., 5., 2.],\n","#  [8., 2., 4.]] (2 Rows, 3 Columns)\n","print(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQBlGL52sGae","executionInfo":{"status":"ok","timestamp":1766553754279,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"79277740-8f1c-4d44-c4e8-5cce2b03162b"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[8., 0., 7.],\n","        [0., 0., 9.]])\n"]}]},{"cell_type":"code","source":["# --- Summation ---\n","# Adds up EVERY element in the tensor -> returns a scalar (0-dimensional tensor).\n","torch.sum(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAgl30YJzzBN","executionInfo":{"status":"ok","timestamp":1766553760988,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"1af25e19-c3be-4824-cb06-c074ccf455fd"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(24.)"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["# Sum along Columns (dim=0)\n","# \"Collapse the rows\". We squash the tensor flat from top to bottom.\n","# Result shape: [3] (1 value for each column).\n","torch.sum(e, dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9o8zMdUosWSs","executionInfo":{"status":"ok","timestamp":1766553769784,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"7b331549-175f-44f0-8420-3bbfef78a2b5"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 8.,  0., 16.])"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["# Sum along Rows (dim=1)\n","# \"Collapse the columns\". We squash the tensor from left to right.\n","# Result shape: [2] (1 value for each row).\n","torch.sum(e, dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Am6Hrdssl90","executionInfo":{"status":"ok","timestamp":1766553783229,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"578b4bce-0024-4365-dabe-150f1140038b"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([15.,  9.])"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["# --- Statistics ---\n","\n","# Mean (Average)\n","# Total Sum / Total Count\n","torch.mean(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocY4Blcoz5IV","executionInfo":{"status":"ok","timestamp":1766553786053,"user_tz":-330,"elapsed":29,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"a276bb92-3e33-45a7-dcf7-b91d0dee5ceb"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["# Mean along Columns (dim=0)\n","# Calculates the average for each column individually.\n","torch.mean(e, dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIXESOkIs8M8","executionInfo":{"status":"ok","timestamp":1766553792617,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"05590f1a-728d-4c04-84cd-3d41624939ba"},"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([4., 0., 8.])"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# Median\n","# Returns the middle value of the flattened tensor.\n","torch.median(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIs7y6cysnFT","executionInfo":{"status":"ok","timestamp":1766553798365,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"9b8a751d-3032-4b84-9886-a8d1dbc94d2e"},"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["# --- Extremes ---\n","\n","# Maximum and Minimum\n","# Returns the largest/smallest value in the entire tensor.\n","torch.max(e)\n","torch.min(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tT3LnUYTz95T","executionInfo":{"status":"ok","timestamp":1766553805453,"user_tz":-330,"elapsed":30,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"8e990f3a-e806-44fc-aab7-89ad58671529"},"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["# --- Product ---\n","\n","# Multiplies all elements together.\n","# Warning: If the tensor contains even a single 0, the result is 0.\n","torch.prod(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIP4CUwasw4Q","executionInfo":{"status":"ok","timestamp":1766553811996,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"7a84b2ba-a255-4bc8-adb4-3600de22fa3a"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["# --- Variance & Standard Deviation ---\n","# These measure the \"spread\" or \"dispersion\" of the data.\n","\n","# Standard Deviation (std)\n","# How much do values typically differ from the mean?\n","torch.std(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAQIjNjwsyLF","executionInfo":{"status":"ok","timestamp":1766553819596,"user_tz":-330,"elapsed":18,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"030d7c6b-373b-46f1-e018-8dd700fe14ef"},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.4272)"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["# Variance (var)\n","# The square of the Standard Deviation.\n","torch.var(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78S1Ggv_s2nC","executionInfo":{"status":"ok","timestamp":1766553824387,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"122c593b-8ac6-4c51-bc4a-cc1c2cd627bd"},"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(19.6000)"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["# --- Indices of Extremes (Argmax/Argmin) ---\n","# Crucial for Classification tasks!\n","# Instead of returning the *value* (e.g., \"9.0\"), these return the *position* (index).\n"],"metadata":{"id":"EOtGIsd9s3UZ","executionInfo":{"status":"ok","timestamp":1766553830591,"user_tz":-330,"elapsed":2,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["# Argmax\n","# Returns the flattened index of the highest value.\n","# If max is at row 1, col 1 (in a 2x3 grid), that's the 4th position (index 4).\n","torch.argmax(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J23C1bwes6TL","executionInfo":{"status":"ok","timestamp":1766553754353,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"5008bc51-74bd-42e4-f809-5db3b1f81edb"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1)"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["# Argmin\n","# Returns the flattened index of the lowest value.\n","torch.argmin(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZN9n7sa0G5w","executionInfo":{"status":"ok","timestamp":1766553842011,"user_tz":-330,"elapsed":42,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"5f3cc751-64e6-4dfd-930c-d3c94eb8505e"},"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1)"]},"metadata":{},"execution_count":111}]},{"cell_type":"markdown","source":["### ðŸ§  Deep Dive: Understanding Dimensions (`dim`)\n","\n","In Data Science (and libraries like NumPy/PyTorch), the `dim` parameter (sometimes called `axis`) tells the computer **which dimension to erase/collapse**.\n","\n","* **`dim=0` (Vertical / Rows):**\n","* Think: \"Squash it top-down.\"\n","* If you have a table of data, this calculates the stat for **each column**.\n","* *Analogy:* Calculating the average height for *each student* across multiple exams? No, that would be rows. This is calculating the average score for **each exam** across all students.\n","\n","\n","* **`dim=1` (Horizontal / Columns):**\n","* Think: \"Squash it left-to-right.\"\n","* This calculates the stat for **each row**.\n","* *Analogy:* Calculating the average grade for **each student** (row) across all their subjects.\n","\n","\n","\n","### ðŸ’¡ Why `argmax`?\n","\n","You will use `torch.argmax` constantly in Deep Learning.\n","\n","* **Scenario:** Your Neural Network classifies an image of a digit (0â€“9).\n","* **Output:** It outputs a probability vector of size 10: `[0.1, 0.05, 0.8, ...]`\n","* **Goal:** You don't care that the score is 0.8; you care that it's in the **2nd index** (representing the digit \"2\").\n","* **Code:** `predicted_digit = torch.argmax(model_output)`\n","5ï¸âƒ£ Shape Summary\n","Operation\tOutput\n","sum(e)\tScalar\n","sum(e, dim=0)\tVector\n","mean(e)\tScalar\n","argmax(e)\tScalar index\n","argmax(e, dim=1)\tVector of indices\n","\n","\n","**Reductions answer questions like:\n","How much?**\n","* How large?\n","* Where is the largest?\n","* How spread out?\n","* Neural networks turn large tensors â†’ small decisions using reductions.\n","\n","**ðŸš€ Why This Matters in Deep Learning**\n","\n","* Loss = reduction over batch\n","* Accuracy = reduction over predictions\n","* Backprop depends on reduction ops\n","* Argmax gives final class prediction\n","\n","**âœ… Rule of Thumb**\n","\n","* Use dim to control what collapses\n","* No dim â†’ everything collapses\n","* argmax returns index, not value"],"metadata":{"id":"gjRSEWUk1zcR"}},{"cell_type":"markdown","source":["### 4. Matrix operations\n","\n","Matrix operations follow **linear algebra rules**, not element-wise rules.\n","\n","> If shapes donâ€™t align â†’ operation is invalid."],"metadata":{"id":"dw_h9fvMtLXw"}},{"cell_type":"code","source":["# 1. Setup Matrices\n","# Create a 2x3 matrix (2 rows, 3 columns) with random integers 0-9.\n","f = torch.randint(size=(2,3), low=0, high=10)\n","\n","# Create a 3x2 matrix (3 rows, 2 columns).\n","# Note: For matrix multiplication (A x B), the columns of A must match the rows of B.\n","g = torch.randint(size=(3,2), low=0, high=10)\n","\n","print(\"Matrix f:\\n\", f)\n","print(\"Matrix g:\\n\", g)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a54MqBBQs7BJ","executionInfo":{"status":"ok","timestamp":1766554461083,"user_tz":-330,"elapsed":48,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"fd5cc699-7c81-43c0-e27e-b39896148aa5"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix f:\n"," tensor([[8, 4, 6],\n","        [6, 9, 7]])\n","Matrix g:\n"," tensor([[7, 4],\n","        [8, 1],\n","        [3, 7]])\n"]}]},{"cell_type":"code","source":["# 2. Matrix Multiplication (MatMul)\n","# Performs the linear algebra \"dot product\" of rows and columns.\n","# Shape: (2,3) x (3,2) -> Result is (2,2).\n","# This is the \"Engine Room\" of Deep Learning (Layers communicating with each other).\n","torch.matmul(f, g)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqQ7sNBctWfS","executionInfo":{"status":"ok","timestamp":1766554476360,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"fa511e14-af7e-4e54-c862-31860736a5d6"},"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[106,  78],\n","        [135,  82]])"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["# --- Vector Operations ---\n","\n","vector1 = torch.tensor([1, 2])\n","vector2 = torch.tensor([3, 4])\n","\n","# 3. Dot Product\n","# Multiplies corresponding elements and sums them up.\n","# (1*3) + (2*4) = 3 + 8 = 11\n","# Conceptually: Measures how much two vectors point in the same direction (Similarity).\n","torch.dot(vector1, vector2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CopN1Oe5tZrD","executionInfo":{"status":"ok","timestamp":1766554488884,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"39e7432a-4aaf-402f-98c0-102f5c116974"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(11)"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["# --- Transformations ---\n","\n","# 4. Transpose\n","# Flips the matrix over its diagonal. Rows become columns, columns become rows.\n","# Arguments: (input, dim0, dim1) -> Swap dimension 0 (rows) with dimension 1 (cols).\n","# Shape change: (2,3) -> (3,2).\n","torch.transpose(f, 0, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Imz3Vq6ta4y","executionInfo":{"status":"ok","timestamp":1766554491931,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"e274f4ed-3169-40a0-eb4e-4b49847d7d84"},"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[8, 6],\n","        [4, 9],\n","        [6, 7]])"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["# --- Linear Algebra Properties ---\n","\n","# We need Float32 for these operations. Determinants/Inverses involve division,\n","# so they don't work on Integers.\n","h = torch.randint(size=(3,3), low=0, high=10, dtype=torch.float32)\n","print(\"Matrix h:\\n\", h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yEfuS9ZKtdSi","executionInfo":{"status":"ok","timestamp":1766554500912,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f7c9b0ef-a194-4b93-c1bc-ea15ff75817d"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix h:\n"," tensor([[3., 8., 2.],\n","        [0., 8., 8.],\n","        [6., 1., 1.]])\n"]}]},{"cell_type":"code","source":["# 5. Determinant (det)\n","# A scalar value describing the \"scaling factor\" of the linear transformation.\n","# If det is 0, the matrix \"squishes\" space into a lower dimension (and has no inverse).\n","torch.det(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqfUsUvttpXZ","executionInfo":{"status":"ok","timestamp":1766554505180,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ff6d9c9e-119d-4b87-c560-a679f30e5d74"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(288.)"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["# 6. Inverse\n","# Finds a matrix H' such that H @ H' = Identity Matrix.\n","# Conceptually: \"Undoing\" the transformation applied by H.\n","# Essential for solving systems of linear equations (though computationally expensive).\n","torch.inverse(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0khPormts14","executionInfo":{"status":"ok","timestamp":1766554514300,"user_tz":-330,"elapsed":41,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"94bdc892-2876-48a6-90c2-53731d97e2ce"},"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000, -0.0208,  0.1667],\n","        [ 0.1667, -0.0312, -0.0833],\n","        [-0.1667,  0.1562,  0.0833]])"]},"metadata":{},"execution_count":119}]},{"cell_type":"markdown","source":["ðŸ§  Deep Dive: The Linear Algebra Connection\n","\n","1. `matmul vs dot`\n","\n","* `torch.dot`: Strictly for 1D arrays (vectors). It returns a single number (scalar). It tells you \"how similar\" two vectors are (unnormalized cosine similarity).\n","\n","* `torch.matmul` (or the `@` operator): The general-purpose tool. It handles 2D matrices (and higher-dimensional batches).\n","\n","> Neural Network Context: When you see $y = Wx + b$, the $Wx$ part is torch.matmul(W, x).\n","\n","2. The Determinant (det)\n","\n","* Grant Sanderson (3Blue1Brown) describes the determinant as the \"Change in Area/Volume\".\n","\n","* If `torch.det(h)` is 2.5, it means the transformation `h` stretches the unit cube to be 2.5x larger.\n","\n","* If `torch.det(h)` is 0, the volume collapses to zero (a flat sheet or line), meaning information is lost and you cannot reverse (invert) the process.\n","\n","3. The Inverse (`inverse`)\n","\n","* Calculating the inverse is the mathematical equivalent of \"running the film backwards.\"\n","\n","* Warning: In production Deep Learning (e.g., Hands-On Machine Learning), we rarely compute the explicit inverse because it is numerically unstable and slow for large matrices. We usually approximate it or use optimization techniques (like Gradient Descent) to find solutions instead.\n","\n"],"metadata":{"id":"lT5agoOM2__a"}},{"cell_type":"markdown","source":["### 5. Comparison Operations\n","\n","Comparison operations compare tensors **element by element** and return\n","**boolean tensors** (`True` / `False`)."],"metadata":{"id":"-lEkBmv5t1nB"}},{"cell_type":"code","source":["# 1. Create Data\n","# Generate two random 2x3 matrices with integers between 0 and 9.\n","i = torch.randint(size=(2,3), low=0, high=10)\n","j = torch.randint(size=(2,3), low=0, high=10)\n","\n","print(\"Tensor i:\\n\", i)\n","print(\"Tensor j:\\n\", j)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G89Keg-xtxUr","executionInfo":{"status":"ok","timestamp":1766554845757,"user_tz":-330,"elapsed":27,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ccb08a96-4dc1-40b1-a6bb-b072e677cf1c"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor i:\n"," tensor([[6, 2, 0],\n","        [1, 8, 6]])\n","Tensor j:\n"," tensor([[5, 6, 4],\n","        [9, 2, 7]])\n"]}]},{"cell_type":"code","source":["# --- Comparison Operations (Element-Wise) ---\n","# All these operations return a \"Boolean Tensor\" (True/False).\n","# They compare i[row][col] with j[row][col].\n","\n","# 2. Greater Than (>)\n","# Returns True if the value in 'i' is strictly larger than 'j'.\n","i > j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5v--5uiuBWW","executionInfo":{"status":"ok","timestamp":1766554853003,"user_tz":-330,"elapsed":42,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"71b3ba55-f813-4614-ad3e-c4734e002079"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ True, False, False],\n","        [False,  True, False]])"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["# 3. Less Than (<)\n","# Returns True if the value in 'i' is strictly smaller than 'j'.\n","i < j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QS0Er1S3-HW","executionInfo":{"status":"ok","timestamp":1766554861426,"user_tz":-330,"elapsed":40,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f5070d1b-19e2-4392-ca4c-9efeb97041fc"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[False,  True,  True],\n","        [ True, False,  True]])"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["# 4. Equal To (==)\n","# Checks for exact equality.\n","# Crucial for calculating accuracy: sum(y_pred == y_true).\n","i == j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mJ4sj2P4BWv","executionInfo":{"status":"ok","timestamp":1766554867674,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"7b019ffd-f4d4-42a4-af25-6adf28cac262"},"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[False, False, False],\n","        [False, False, False]])"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["# 5. Not Equal To (!=)\n","# Returns True if values are different.\n","i != j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNMXrTzn4CaR","executionInfo":{"status":"ok","timestamp":1766554872262,"user_tz":-330,"elapsed":106,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"73eab4e7-f69c-44d2-e6d7-ef137bbd164e"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True, True, True],\n","        [True, True, True]])"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["# 6. Greater Than or Equal To (>=)\n","# Returns True if 'i' is larger than OR equal to 'j'.\n","# Included based on your comment request.\n","i >= j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9TknuTL4DjV","executionInfo":{"status":"ok","timestamp":1766554876743,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"6cd6a312-d397-4f1f-a9a5-c593d6e42db5"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ True, False, False],\n","        [False,  True, False]])"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["# 7. Less Than or Equal To (<=)\n","# Returns True if 'i' is smaller than OR equal to 'j'.\n","# Included based on your comment request.\n","i <= j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6ZwCFi74E4T","executionInfo":{"status":"ok","timestamp":1766554882320,"user_tz":-330,"elapsed":42,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"50ee33c8-d652-478a-d478-956442377d9d"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[False,  True,  True],\n","        [ True, False,  True]])"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","source":["### ðŸ§  Deep Dive: Boolean Masks\n","\n","In libraries like PyTorch and NumPy (the backbone of the Python Data Science Handbook), these operations create what we call a Boolean Mask.\n","\n","1. What is a Boolean Mask?\n","\n","> It is a tensor of the same shape as your data, but filled with True and False instead of numbers.\n","\n","> * True = \"Yes, this specific pixel/number satisfies your condition.\"\n","\n","> * False = \"No, it does not.\"\n","\n","2. Real-World Use Cases\n","\n","> Calculating Accuracy: To find out how well your model performed, you compare predictions to targets:\n","\n","```\n","correct_predictions = (predictions == targets) # Boolean Mask\n","\n","accuracy = correct_predictions.sum() / len(targets)\n","```\n","\n","> **ReLU Activation (Manual)**:\n","\n","> The ReLU function is essentially \"keep positive numbers, set negatives to zero.\"\n","\n","```\n","x[x < 0] = 0  # \"Find all values < 0 and set them to 0\"\n","```\n","\n","This technique (masking) is faster than writing a for loop to check every number.\n","\n"],"metadata":{"id":"s6trj82J4RZ6"}},{"cell_type":"markdown","source":["### 6. Special functions\n","\n","Special functions introduce **non-linearity** into models.\n","Without them, neural networks would be only linear â†’ not powerful."],"metadata":{"id":"jd9JzlO1uaf3"}},{"cell_type":"code","source":["# 1. Create a Tensor\n","# We use float32 because log, exp, sqrt, and sigmoid require floating-point numbers.\n","# If you used integers, PyTorch would throw a runtime error.\n","k = torch.randint(size=(2,3), low=0, high=10, dtype=torch.float32)\n","print(\"Original Tensor k:\\n\", k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKU6tQpyuY0M","executionInfo":{"status":"ok","timestamp":1766555444101,"user_tz":-330,"elapsed":72,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"1fbd18a7-3d0b-4b7b-878f-926cc8b81dfa"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Tensor k:\n"," tensor([[5., 6., 7.],\n","        [9., 9., 1.]])\n"]}]},{"cell_type":"code","source":["# --- Mathematical Transformations ---\n","\n","# 2. Natural Logarithm (ln)\n","# Computes natural log (ln) Applied element-wise\n","# Input must be positive as undefined for x <= 0 (returns -inf or nan).\n","# Used heavily in Loss Functions (like Cross-Entropy Loss).\n","torch.log(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gl1dhdVuDOE","executionInfo":{"status":"ok","timestamp":1766555459458,"user_tz":-330,"elapsed":45,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"ee32d564-54d1-48bc-e8e2-9c86cd975d3f"},"execution_count":129,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.6094, 1.7918, 1.9459],\n","        [2.1972, 2.1972, 0.0000]])"]},"metadata":{},"execution_count":129}]},{"cell_type":"code","source":["# 3. Exponential (e^x)\n","# Calculates Euler's number (e â‰ˆ 2.718) raised to the power of k.\n","# This is the inverse of log. Used to undo log-transformations.\n","torch.exp(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQSpBdkbujck","executionInfo":{"status":"ok","timestamp":1766555465423,"user_tz":-330,"elapsed":24,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"7842bcb6-7226-4d7f-93ec-80b05b95831a"},"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.4841e+02, 4.0343e+02, 1.0966e+03],\n","        [8.1031e+03, 8.1031e+03, 2.7183e+00]])"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["# 4. Square Root\n","# Returns the square root of each element.\n","torch.sqrt(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTDfXdbVukh0","executionInfo":{"status":"ok","timestamp":1766555471359,"user_tz":-330,"elapsed":17,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"12cc3368-1326-4a61-81ab-b745e58adb4d"},"execution_count":131,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.2361, 2.4495, 2.6458],\n","        [3.0000, 3.0000, 1.0000]])"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","source":["# --- Activation Functions (The Heart of Deep Learning) ---\n","\n","# 5. Sigmoid\n","# Squashes every number into the range (0, 1).\n","# Formula: Ïƒ(x) = 1 / (1 + eâ»Ë£)\n","# Use Case: Binary Classification (converting a raw score into a probability).\n","torch.sigmoid(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-rbMIVPunhr","executionInfo":{"status":"ok","timestamp":1766555482609,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"fffb1375-cec0-4141-b3dc-78bce2f3ba0d"},"execution_count":132,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.9933, 0.9975, 0.9991],\n","        [0.9999, 0.9999, 0.7311]])"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["# 6. Softmax\n","# Converts values into probabilities\n","# Converts a vector of numbers into a \"Probability Distribution\" that sums to 1.\n","# dim=0 means \"make the columns sum to 1\".\n","# dim=1 means \"make the rows sum to 1\".\n","# Use Case: Multi-Class Classification (e.g., \"Is this image a Cat, Dog, or Bird?\").\n","torch.softmax(k, dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X74chVfQusqf","executionInfo":{"status":"ok","timestamp":1766555491822,"user_tz":-330,"elapsed":30,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"9f9a98e5-1141-4ff8-aa55-3399b76fab2e"},"execution_count":133,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0180, 0.0474, 0.9975],\n","        [0.9820, 0.9526, 0.0025]])"]},"metadata":{},"execution_count":133}]},{"cell_type":"code","source":["# 7. ReLU (Rectified Linear Unit)\n","# The most popular activation function in modern AI.\n","# Formula: max(0, x).\n","# Logic: \"If it's positive, keep it. If it's negative, turn it off (make it 0).\"\n","# Use Case: Hidden layers of nearly all Deep Neural Networks (CNNs, Transformers).\n","torch.relu(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnLG2JbyutvC","executionInfo":{"status":"ok","timestamp":1766555500822,"user_tz":-330,"elapsed":55,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"3d3e1064-2f0c-439c-b4ff-da1c4af2aed0"},"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[5., 6., 7.],\n","        [9., 9., 1.]])"]},"metadata":{},"execution_count":134}]},{"cell_type":"markdown","source":["ðŸ§  Deep Dive: Activation Functions\n","\n","These \"special functions\" are what make Neural Networks learn complex patterns. Without them, a neural network is just a giant Linear Regression model.\n","\n","1. Sigmoid vs. ReLU\n","\n","> * Sigmoid: Used to be popular, but it has a problem called \"Vanishing Gradients\" (for very high or low numbers, the slope becomes flat/zero, and the model stops learning).\n","\n","> * ReLU: Solved this problem. It is computationally fast (just a max check) and keeps gradients alive for positive numbers.\n","\n","2. The Softmax Magic\n","\n","If your model outputs raw scores (logits) like [2.0, 1.0, 0.1], you can't say \"There is a 200% chance it's class A\". Softmax fixes this by normalizing them relative to each other:\n","\n","* Input: [2.0, 1.0, 0.1]\n","\n","* Output: [0.7, 0.2, 0.1] (approx) $\\rightarrow$ \"70% Class A, 20% Class B, 10% Class C\".\n","\n","* Note: Notice the dim=0 in your code. This is crucial. If you get the dimension wrong, you normalize the wrong batch of numbers!"],"metadata":{"id":"6O1JgFsj6ioT"}},{"cell_type":"markdown","source":["### Detailed Explanation\n","\n","1. **Element-Wise vs. Matrix Operations**\n","The most critical distinction in Linear Algebra libraries is between `*` and `matmul`.\n","* **Element-wise `(a * b)`**: Matches corresponding pixels/cells. Used for masking (e.g., set specific values to 0) or applying activation functions.\n","* **Matrix Multiplication `(a @ b or torch.matmul)`**: The \"Row times Column\" rule used in Neural Network layers.\n","2. **Rounding Behavior**\n","\n","PyTorch (like NumPy) often defaults to **\"Round Half to Even\"** (also known as Banker's Rounding).\n","* Standard Rounding: 2.5 $\\rightarrow$ 3\n","* Banker's Rounding: 2.5 $\\rightarrow$ 2 (Even), 3.5 $\\rightarrow$ 4 (Even).\n","* Why? Standard rounding introduces a slight upward bias in large datasets. Banker's rounding averages out errors over time.\n","3. The Power of `torch.clamp`\n","\n","Clamping is essential for **Gradient Clipping** and **Probability Safety**.* **Exploding Gradients**: In RNNs, gradients can become huge (NaN). Using `clamp` keeps them manageable.\n","* **Log Safety**: If you try to calculate `log(x)` and `x` is 0, you get `-inf`. A common trick is `torch.log(torch.clamp(x, min=1e-9))` to prevent crashes.\n","\n","###âœ… Rule of Thumb\n","\n","* `+ - * / ** %` $\\rightarrow$ element-wise\n","\n","* `@` or `torch.matmul()` $\\rightarrow$ matrix multiplication"],"metadata":{"id":"d_8ox6bxoI9q"}},{"cell_type":"markdown","source":["## Inplace Operations"],"metadata":{"id":"JQ7im-Mz9Mu9"}},{"cell_type":"code","source":["# 1. Initialize Tensors\n","# Create two random matrices of size 2x3\n","m = torch.rand(2,3)\n","n = torch.rand(2,3)\n","\n","print(\"Original m:\", m)\n","print(\"Original n:\", n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKVMTBq7uufZ","executionInfo":{"status":"ok","timestamp":1766553754520,"user_tz":-330,"elapsed":15,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"85603c3f-c746-40cd-b29d-16e2ca553769"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Original m: tensor([[0.6574, 0.3451, 0.0453],\n","        [0.9798, 0.5548, 0.6868]])\n","Original n: tensor([[0.4920, 0.0748, 0.9605],\n","        [0.3271, 0.0103, 0.9516]])\n"]}]},{"cell_type":"code","source":["# 2. In-Place Addition\n","# The underscore (_) at the end of the method name is a PyTorch convention.\n","# It signifies that the operation happens IN-PLACE.\n","# This modifies 'm' directly in memory using the values from 'n'.\n","# No new memory is allocated for the result.\n","m.add_(n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmN2o2Ge_j8h","executionInfo":{"status":"ok","timestamp":1766553754520,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"78ece419-e9fa-432b-a906-1beaabec09bb"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.1494, 0.4199, 1.0058],\n","        [1.3069, 0.5650, 1.6384]])"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["# 'm' has now changed.\n","print(\"Modified m:\", m)\n","# 'n' remains the same.\n","print(\"Unchanged n:\", n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JULn_7_ApWC8","executionInfo":{"status":"ok","timestamp":1766553754529,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"1eccb2a5-4549-46a6-e478-19955f98c836"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Modified m: tensor([[1.1494, 0.4199, 1.0058],\n","        [1.3069, 0.5650, 1.6384]])\n","Unchanged n: tensor([[0.4920, 0.0748, 0.9605],\n","        [0.3271, 0.0103, 0.9516]])\n"]}]},{"cell_type":"code","source":["# 3. Standard ReLU (Out-of-Place)\n","# Applies the Rectified Linear Unit function (max(0, x)).\n","# # torch.relu(m) is an OUT-OF-PLACE operation\n","# It returns a new tensor where all negative values are replaced with 0\n","# This creates and returns a NEW tensor. The original 'm' is NOT touched.\n","new_tensor = torch.relu(m)"],"metadata":{"id":"8OhePrDbAmwh","executionInfo":{"status":"ok","timestamp":1766553754531,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["m"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPd942ZOqePP","executionInfo":{"status":"ok","timestamp":1766553754536,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"c9b7e8ae-3a5b-44ff-ded9-97dd3ef88a77"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.1494, 0.4199, 1.0058],\n","        [1.3069, 0.5650, 1.6384]])"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["# 4. In-Place ReLU\n","# Note the underscore again: .relu_()\n","# This applies the function directly to the data inside 'm'.\n","# Any negative numbers in 'm' are replaced by 0 inside the same memory block.\n","m.relu_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_s6WQ0pAuTG","executionInfo":{"status":"ok","timestamp":1766553754542,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"aa919f20-cab9-4cd5-fb59-5461a43ffe26"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.1494, 0.4199, 1.0058],\n","        [1.3069, 0.5650, 1.6384]])"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["print(\"Final In-Place Modified m:\", m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sucQ4iPYAyqn","executionInfo":{"status":"ok","timestamp":1766553754578,"user_tz":-330,"elapsed":36,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"2f984519-dc99-4dd0-d176-fe664056cce9"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Final In-Place Modified m: tensor([[1.1494, 0.4199, 1.0058],\n","        [1.3069, 0.5650, 1.6384]])\n"]}]},{"cell_type":"markdown","source":["ReLU vs ReLU_\n","\n","| Operation       | Modifies Tensor? | Returns New Tensor |\n","| --------------- | ---------------- | ------------------ |\n","| `torch.relu(m)` | âŒ No             | âœ… Yes              |\n","| `m.relu_()`     | âœ… Yes            | âŒ No               |\n"],"metadata":{"id":"LVxsXD6dq1-x"}},{"cell_type":"markdown","source":["## Copying a Tensor"],"metadata":{"id":"7-SgjcqnCN9P"}},{"cell_type":"code","source":["# 1. Create a Tensor\n","a = torch.rand(2,3)\n","print(\"Original a:\\n\", a)"],"metadata":{"id":"W1SwQS8jEnW2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766553754579,"user_tz":-330,"elapsed":27,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"501c13f7-2583-4c7d-d64e-eec67be1614d"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Original a:\n"," tensor([[0.2855, 0.2324, 0.9141],\n","        [0.7668, 0.1659, 0.4393]])\n"]}]},{"cell_type":"code","source":["# --- SCENARIO 1: Reference Assignment (Aliasing) ---\n","# We assign 'a' to 'b'. In Python, this DOES NOT create a new tensor.\n","# It effectively creates a new label 'b' that points to the SAME memory address as 'a'.\n","b = a"],"metadata":{"id":"mfswuT0OrY5W","executionInfo":{"status":"ok","timestamp":1766553754581,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["# Modification:\n","# We change the value at row 0, col 0 of 'a'.\n","a[0][0] = 0"],"metadata":{"id":"fFDgACNVraBb","executionInfo":{"status":"ok","timestamp":1766553754583,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["# Result:\n","# Because 'b' points to the same object, 'b' is ALSO modified.\n","print(\"\\n--- After Reference Assignment ---\")\n","print(\"Modified a:\\n\", a)\n","print(\"Modified b (reflects a):\\n\", b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"otmJu8BerbuR","executionInfo":{"status":"ok","timestamp":1766553754598,"user_tz":-330,"elapsed":15,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"0379fe5a-935f-4816-b3c6-d158625af885"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- After Reference Assignment ---\n","Modified a:\n"," tensor([[0.0000, 0.2324, 0.9141],\n","        [0.7668, 0.1659, 0.4393]])\n","Modified b (reflects a):\n"," tensor([[0.0000, 0.2324, 0.9141],\n","        [0.7668, 0.1659, 0.4393]])\n"]}]},{"cell_type":"code","source":["# Proof:\n","# The id() function returns the unique memory address of the object.\n","# These two numbers will be IDENTICAL.\n","print(f\"Address of a: {id(a)}\")\n","print(f\"Address of b: {id(b)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqtJvT71re53","executionInfo":{"status":"ok","timestamp":1766553754609,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"038a9f2c-7217-42f5-9718-b97b58650e86"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Address of a: 139246786257904\n","Address of b: 139246786257904\n"]}]},{"cell_type":"code","source":["# --- SCENARIO 2: Cloning (True Copy) ---\n","# .clone() creates a brand new tensor in a NEW memory block,\n","# copying all the data from 'a' into it.\n","b = a.clone()"],"metadata":{"id":"WRTXKS5krgTe","executionInfo":{"status":"ok","timestamp":1766553754621,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["# Modification:\n","# We change 'a' again (setting top-left to 10).\n","a[0][0] = 10"],"metadata":{"id":"AIk-2EUTriAn","executionInfo":{"status":"ok","timestamp":1766553754630,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["# Result:\n","# 'a' changes, but 'b' REMAINS THE SAME as it was at the moment of cloning.\n","# They are now independent.\n","print(\"\\n--- After Cloning ---\")\n","print(\"Modified a (is 10):\\n\", a)\n","print(\"Independent b (is 0):\\n\", b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPAqF766rjt2","executionInfo":{"status":"ok","timestamp":1766553754640,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"717a90d7-6024-459d-a2b8-d91e874fa9d2"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- After Cloning ---\n","Modified a (is 10):\n"," tensor([[10.0000,  0.2324,  0.9141],\n","        [ 0.7668,  0.1659,  0.4393]])\n","Independent b (is 0):\n"," tensor([[0.0000, 0.2324, 0.9141],\n","        [0.7668, 0.1659, 0.4393]])\n"]}]},{"cell_type":"code","source":["# Proof:\n","# These two numbers will be DIFFERENT.\n","print(f\"Address of a: {id(a)}\")\n","print(f\"Address of b: {id(b)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53lp9YbVrlqT","executionInfo":{"status":"ok","timestamp":1766553754645,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"560f57de-9345-4509-8d84-d63cdf863f7b"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["Address of a: 139246786257904\n","Address of b: 139242769653408\n"]}]},{"cell_type":"markdown","source":["## Tensor Operations on GPU"],"metadata":{"id":"tR4HhJ6usM9L"}},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2L-5a0zsPse","executionInfo":{"status":"ok","timestamp":1766553754667,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"a9fec59a-59d1-4108-8b3b-e1ad8d7bf07d"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"fLVdjWVFsVVs","executionInfo":{"status":"ok","timestamp":1766553754668,"user_tz":-330,"elapsed":2,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["# creating a new tensor on GPU\n","torch.rand((2, 3), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HkBK0MI-s2Bp","executionInfo":{"status":"ok","timestamp":1766553755076,"user_tz":-330,"elapsed":408,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"23068037-a79f-4a80-ca49-da66d0c79970"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3563, 0.0303, 0.7088],\n","        [0.2009, 0.0224, 0.9896]], device='cuda:0')"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["# moving an existing tensor to GPU\n","a = torch.rand((2, 3))\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYxWs6cctE47","executionInfo":{"status":"ok","timestamp":1766553755077,"user_tz":-330,"elapsed":49,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"34e4ca20-017d-40f8-c527-141018107967"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2243, 0.8935, 0.0497],\n","        [0.1780, 0.3011, 0.1893]])"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["b = a.to(device)\n","b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpNh-tk2tPiu","executionInfo":{"status":"ok","timestamp":1766553755080,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"f4845ebf-8567-46db-ff28-f20abb438ed8"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2243, 0.8935, 0.0497],\n","        [0.1780, 0.3011, 0.1893]], device='cuda:0')"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["import time\n","import torch\n","\n","# -------------------------------\n","# Device selection\n","# -------------------------------\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# Matrix size (SAFE)\n","# -------------------------------\n","\n","size = 1000  # CPU-safe, GPU-safe\n","\n","# -------------------------------\n","# CPU computation\n","# -------------------------------\n","\n","matrix_cpu1 = torch.rand(size, size)\n","matrix_cpu2 = torch.rand(size, size)\n","\n","start_time = time.time()\n","result_cpu = torch.matmul(matrix_cpu1, matrix_cpu2)\n","end_time = time.time()\n","\n","print(f\"CPU time: {end_time - start_time:.4f} seconds\")\n","\n","# -------------------------------\n","# GPU computation\n","# -------------------------------\n","\n","matrix_gpu1 = matrix_cpu1.to(device)\n","matrix_gpu2 = matrix_cpu2.to(device)\n","\n","# IMPORTANT: synchronize before timing\n","torch.cuda.synchronize()\n","start_time = time.time()\n","\n","result_gpu = torch.matmul(matrix_gpu1, matrix_gpu2)\n","\n","# IMPORTANT: synchronize after computation\n","torch.cuda.synchronize()\n","end_time = time.time()\n","\n","print(f\"GPU time: {end_time - start_time:.4f} seconds\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMIUXTWYtVWs","executionInfo":{"status":"ok","timestamp":1766553755173,"user_tz":-330,"elapsed":93,"user":{"displayName":"Anuj Chaudhary","userId":"03934067282409377867"}},"outputId":"1d459c57-dffa-48c1-e9e5-84847e294a00"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","CPU time: 0.0398 seconds\n","GPU time: 0.1096 seconds\n"]}]},{"cell_type":"markdown","source":["\n","---\n","\n","````markdown\n","# ðŸ§  PyTorch Tensor Creation â€” Practice Exercises\n","\n","> **Instructions**\n","> - Try to answer **without running code first**\n","> - Write your answer on paper or in a code cell\n","> - Expand the hidden section **only after committing**\n","\n","---\n","\n","## â“ Question 1\n","What is the **shape** of the following tensor?\n","\n","```python\n","torch.zeros(4, 2)\n","````\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","**Shape:** `(4, 2)`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 2\n","\n","What is the **key difference** between `torch.empty()` and `torch.zeros()`?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","* `torch.empty()` allocates memory **without initializing values**\n","* `torch.zeros()` initializes **all values to zero**\n","\n","</details>\n","\n","---\n","\n","## â“ Question 3\n","\n","What type of values does `torch.rand(3, 3)` generate?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","Random floating-point numbers drawn from a **uniform distribution between 0 and 1**\n","\n","</details>\n","\n","---\n","\n","## â“ Question 4\n","\n","What will be the output of this code?\n","\n","```python\n","torch.manual_seed(42)\n","a = torch.rand(2, 2)\n","\n","torch.manual_seed(42)\n","b = torch.rand(2, 2)\n","\n","a == b\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","A tensor of `True` values â€” both tensors are **identical** because the seed was reset.\n","\n","</details>\n","\n","---\n","\n","## â“ Question 5\n","\n","How is `torch.arange()` **different** from `torch.linspace()`?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","* `arange()` â†’ uses a **step size**\n","* `linspace()` â†’ uses a **fixed number of points**\n","\n","</details>\n","\n","---\n","\n","## â“ Question 6\n","\n","Predict the output:\n","\n","```python\n","torch.arange(1, 10, 3)\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","```text\n","tensor([1, 4, 7])\n","```\n","\n","</details>\n","\n","---\n","\n","## â“ Question 7\n","\n","Predict the output:\n","\n","```python\n","torch.linspace(0, 1, 5)\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","```text\n","tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n","```\n","\n","</details>\n","\n","---\n","\n","## â“ Question 8\n","\n","What does `torch.eye(4)` create, and where are the `1`s located?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","A **4Ã—4 identity matrix** with `1`s on the **main diagonal**\n","\n","</details>\n","\n","---\n","\n","## â“ Question 9\n","\n","What is the output shape of this tensor?\n","\n","```python\n","torch.full((2, 5), 7)\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","**Shape:** `(2, 5)`\n","All values are `7`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 10\n","\n","Which function should you use if you want to **convert a Python list into a tensor**?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","`torch.tensor()`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 11 (Conceptual)\n","\n","Why is setting `torch.manual_seed()` important in machine learning experiments?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","It ensures **reproducibility**, making experiments debuggable and comparable.\n","\n","</details>\n","\n","---\n","\n","## â“ Question 12 (Tricky)\n","\n","Is this statement true or false?\n","\n","> Two calls to `torch.rand()` without setting a seed will always produce the same output.\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","âŒ **False** â€” outputs differ unless the random seed is fixed.\n","\n","</details>\n","\n","---\n","\n","## ðŸ§  Self-Assessment\n","\n","* 10â€“12 correct â†’ ðŸ”¥ **Excellent**\n","* 7â€“9 correct â†’ ðŸ‘ **Solid foundation**\n","* <7 â†’ ðŸ” Revisit tensor creation basics\n","\n","---\n","\n","## ðŸš€ Next-Level Challenge (Optional)\n","\n","Try to create:\n","\n","1. A **3Ã—3 tensor** filled with `-1`\n","2. A tensor with values **[0, 0.1, 0.2, ..., 1.0]**\n","3. A **5Ã—5 identity matrix multiplied by 2**\n","\n","(Write code before checking docs!)\n","\n","```\n","\n","---\n"],"metadata":{"id":"q1wNyZB0dHCk"}},{"cell_type":"markdown","source":["Awesome â€” letâ€™s **lock this in with active recall** ðŸ§ ðŸ”¥\n","Below is a **PyTorch tensor shapes & `_like()` functions exercise set** with **12 questions**, and **answers hidden** using collapsible sections.\n","\n","You can paste this **directly into a Jupyter / Colab Markdown cell** ðŸ‘‡\n","\n","---\n","\n","````markdown\n","# ðŸ§  PyTorch Tensor Shapes & `_like()` â€” Practice Exercises\n","\n","> **Instructions**\n","> - Do NOT run code first\n","> - Predict shapes, values, or behavior mentally\n","> - Expand answers only after committing\n","\n","---\n","\n","## â“ Question 1\n","What is the **shape** of the tensor below?\n","\n","```python\n","x = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])\n","x.shape\n","````\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","`torch.Size([2, 3])`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 2\n","\n","What does the **first number** in `x.shape` represent?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","Number of **rows** (or samples / batch elements)\n","\n","</details>\n","\n","---\n","\n","## â“ Question 3\n","\n","Predict the **shape** of this tensor:\n","\n","```python\n","torch.zeros_like(x)\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","Same shape as `x` â†’ `(2, 3)`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 4\n","\n","What is the **main danger** of using `torch.empty_like()`?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","It contains **uninitialized garbage values** from memory.\n","\n","</details>\n","\n","---\n","\n","## â“ Question 5\n","\n","True or False:\n","\n","> `_like()` functions automatically copy the shape of the input tensor.\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","âœ… **True**\n","\n","</details>\n","\n","---\n","\n","## â“ Question 6\n","\n","Why does this code specify `dtype=torch.float32`?\n","\n","```python\n","torch.rand_like(x, dtype=torch.float32)\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","Because `x` is an **integer tensor**, but random values must be **floating-point**.\n","\n","</details>\n","\n","---\n","\n","## â“ Question 7\n","\n","What happens if you run `torch.rand_like(x)` **without** specifying `dtype`?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","It raises an error or produces incorrect behavior because random values cannot be stored in an integer tensor.\n","\n","</details>\n","\n","---\n","\n","## â“ Question 8\n","\n","Which function would you use to create a tensor that:\n","\n","* Has the same shape as `x`\n","* Is filled with `1`s\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","`torch.ones_like(x)`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 9\n","\n","Predict the output shape:\n","\n","```python\n","y = torch.rand_like(x)\n","y.shape\n","```\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","Same as `x` â†’ `(2, 3)`\n","\n","</details>\n","\n","---\n","\n","## â“ Question 10\n","\n","Fill in the blank:\n","\n","> `_like()` functions help avoid __________ bugs.\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","**Shape mismatch** bugs\n","\n","</details>\n","\n","---\n","\n","## â“ Question 11 (Tricky)\n","\n","Is this statement correct?\n","\n","> `torch.zeros_like(x)` copies the values of `x` and replaces them with zeros.\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","âŒ **False** â€” it copies only the **shape and dtype**, not values.\n","\n","</details>\n","\n","---\n","\n","## â“ Question 12 (Conceptual)\n","\n","Why are `_like()` functions preferred over hard-coding dimensions?\n","\n","<details>\n","<summary>âœ… Show Answer</summary>\n","\n","They make code **robust, scalable, and safe** when tensor shapes change (e.g., batch size).\n","\n","</details>\n","\n","---\n","\n","## ðŸ§  Self-Check\n","\n","* 10â€“12 correct â†’ ðŸ”¥ Excellent grasp\n","* 7â€“9 correct â†’ ðŸ‘ Solid foundation\n","* <7 â†’ ðŸ” Revisit shapes and `_like()` basics\n","\n","---\n","\n","## ðŸš€ Bonus Challenge (Optional)\n","\n","Without running code, predict:\n","\n","```python\n","a = torch.ones_like(x)\n","b = torch.zeros_like(a)\n","c = torch.rand_like(b, dtype=torch.float32)\n","```\n","\n","* What is the shape of `c`?\n","* What is the datatype of `c`?\n","\n","```\n","\n","---\n","\n","If you want next:\n","- ðŸ§© **Broadcasting prediction puzzles**\n","- ðŸ”¥ **Interview-style shape traps**\n","- ðŸ§  **Visual diagrams for tensor flow**\n","\n","Just tell me how hard you want it ðŸ˜„\n","```\n"],"metadata":{"id":"8lDuKKt2mM7o"}}]}